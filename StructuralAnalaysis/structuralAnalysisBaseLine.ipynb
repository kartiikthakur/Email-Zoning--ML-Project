{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"logo.jpg\" width=\"700\" />\n",
    "\n",
    "# Email Structural analysis using a Neural Network (NN) approach for TA2 layer of PANACEA project\n",
    "\n",
    "The purpose of this code is to present an approach for __detecting the central parts of an email__. The main idea, is to create a NN that can be used for detecting __greetings, content and signature elements__ associated to the textual content of a message.\n",
    "\n",
    "__Code main elements:__\n",
    "\n",
    "1. All the code was implemented in Python 3.7.1 https://www.python.org/\n",
    "2. The dataset used is a labeled subset of the well known Enron dataset and Apache mailing list. More information can be found here: https://github.com/HPI-Information-Systems/Quagga/blob/master/Datasets/DATA.md \n",
    "3. The  Python packages required to run the programs are the following:\n",
    "    * Jupyter notebook (Python interactive prompt) http://jupyter.org/index.html\n",
    "    * Matplotlib (visualization) https://matplotlib.org/\n",
    "    * Numpy (mathematical functions) http://www.numpy.org/\n",
    "    * Scipy (mathematical functions) https://www.scipy.org/\n",
    "    * NLTK (Natural Language Processing) https://www.nltk.org/\n",
    "    * sklearn (Machine Learning) http://scikit-learn.org/stable/\n",
    "    * Gensim https://radimrehurek.com/gensim/\n",
    "    \n",
    "__For more information see:__\n",
    "\n",
    "1. https://medium.com/datadriveninvestor/building-neural-network-using-keras-for-classification-3a3656c726c1\n",
    "2. https://github.com/HPI-Information-Systems/Quagga"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predefined tool\n",
    "\n",
    "\n",
    "Check an existing package called \"Quagga\" for detecting the parts of an email: https://github.com/HPI-Information-Systems/QuaggaLib\n",
    "\n",
    "The package classify each text line into one of five types: __Header, Body, Body/Intro, Body/Outro, Body/Signature.__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Quagga'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-2b9d04022d08>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m from Quagga import (Quagga, \n\u001b[0m\u001b[0;32m      2\u001b[0m             \u001b[0mEmailDirectoryReader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             \u001b[0mListReaderRawEmailTexts\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m             \u001b[0mListReaderExtractedBodies\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m             \u001b[0mTempQuaggaReader\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Quagga'"
     ]
    }
   ],
   "source": [
    "from Quagga import (Quagga, \n",
    "            EmailDirectoryReader, \n",
    "            ListReaderRawEmailTexts, \n",
    "            ListReaderExtractedBodies, \n",
    "            TempQuaggaReader, \n",
    "            ModelBuilder)\n",
    "from Quagga.Utils.BlockParser.BlockParser import BlockParser\n",
    "\n",
    "quagga = Quagga(ListReaderExtractedBodies(''), \n",
    "                output_dir='', # optional, saves to directory if set\n",
    "                model_builder=ModelBuilder(with_crf=True, zones=5, trainset='enron'), # optional\n",
    "                block_parser=BlockParser()) # optional\n",
    "email_body_text= (\"Hi,\\nI am trying to use the ConnectedComponent algorithm of GraphFrames but by default it\"+\n",
    "                 \"needs a checkpoint directory. As I am running my spark cluster with S3 as the DFS and do not\"+\n",
    "                 \" have access to HDFS file system I tried using a s3 directory as checkpoint directory but I run\"+\n",
    "                 \" into below exception:\\nRegards Sumit Chawla\\n Susan Priest\\nClasses of '77 and '81\")\n",
    "classified_lines = quagga.predict(email_body_text)\n",
    "print(classified_lines)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create our own classification model\n",
    "\n",
    "1\\. Obtain the current Jupyter notebook path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\School\\ILS\\StructuralAnalaysis\n"
     ]
    }
   ],
   "source": [
    "#Operating system functions for interacting with folders and files\n",
    "import os\n",
    "noteBookPath= os.getcwd()\n",
    "os.chdir(noteBookPath)\n",
    "print (noteBookPath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2\\. Extract representative samples (all elements labeled as Body, Body/Intro, Body/Outro, Body/Signature) from Quagga training and test datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: 'dataset' exists\n",
      "Directory: 'experiments' exists\n",
      "datasetPath variable dont exist, applying default one\n",
      "Training document already exist\n",
      "Test document already exist\n"
     ]
    }
   ],
   "source": [
    "#Encoding functions for opening files in the correct format\n",
    "import codecs\n",
    "import errno\n",
    "#Operating system functions for interacting with folders and files\n",
    "import os\n",
    "from os import listdir\n",
    "import sys\n",
    "import traceback\n",
    "#Mathematical functions to handle vectors\n",
    "import numpy as np\n",
    "#object-serializing functions\n",
    "import pickle\n",
    "#Calendar functions for timestamp\n",
    "import datetime\n",
    "import time\n",
    "#Encoding functions to handle Json files\n",
    "import json\n",
    "#Text maipulation functions (eliminate certain words for instance)\n",
    "import re\n",
    "\n",
    "#Check if the notebook path is already loaded\n",
    "try:  \n",
    "    noteBookPath\n",
    "except NameError:\n",
    "    print (\"NotebookPath variable dont exist, applying default one\")\n",
    "    noteBookPath= os.getcwd()\n",
    "    pass\n",
    "    \n",
    "#Check if dataset path exist\n",
    "datasetFolder=\"dataset\"\n",
    "try:\n",
    "    datasetsPath=os.path.join(noteBookPath,datasetFolder) \n",
    "    if not os.path.isdir(datasetsPath): raise Exception(\"'Dataset' folder dont exist\")\n",
    "    else: \n",
    "        print (\"Directory: '\"+ datasetFolder+\"' exists\")\n",
    "        pass\n",
    "except SystemExit as e:\n",
    "    print(e)\n",
    "\n",
    "#Create experiments folder if not exists\n",
    "dirName=\"experiments\"\n",
    "try:\n",
    "    os.mkdir(os.path.join(noteBookPath,dirName) )\n",
    "    print (\"Directory: '\"+dirName+\"' Created\") \n",
    "except OSError as e:\n",
    "    if e.errno == errno.EEXIST:\n",
    "        print (\"Directory: '\"+ dirName+\"' exists\")\n",
    "        pass\n",
    "    else:\n",
    "        raise \n",
    "except:\n",
    "    print (\"Unexpected error\")\n",
    "    pass  \n",
    "\n",
    "#Check if the experiments folder path exist\n",
    "try:  \n",
    "    experimentsPath\n",
    "except NameError:\n",
    "    print (\"datasetPath variable dont exist, applying default one\")\n",
    "    experimentsPath=os.path.join(noteBookPath,dirName)\n",
    "    pass\n",
    "\n",
    "#Python Script\n",
    "try:\n",
    "    \n",
    "    document = \"structuralAnaysisTraining.txt\"\n",
    "    filePath = os.path.join(experimentsPath,document)\n",
    "    \n",
    "    document2 = \"structuralAnaysisTest.txt\"\n",
    "    filePath2 = os.path.join(experimentsPath,document2)\n",
    "    \n",
    "    contentType=[\"Body\", \"Body/Intro\", \"Body/Outro\", \"Body/Signature\"]\n",
    "    \n",
    "    if not (os.path.isfile(filePath)):\n",
    "\n",
    "        print(\"Create trainig document\")\n",
    "        trainingSamples=[]\n",
    "        \n",
    "        textStatistics={\"Body\":[], \"Body/Intro\":[], \"Body/Outro\":[], \"Body/Signature\":[]}\n",
    "        \n",
    "        dataSetsTraining=[\"enronTrain\",\"apacheTrain\"]\n",
    "        for dataSetName in dataSetsTraining:\n",
    "            datasetPath=os.path.join(datasetsPath,dataSetName)\n",
    "            emailSamples = [f for f in listdir(datasetPath) if f.endswith(\".ann\")]\n",
    "            \n",
    "            for emailName in emailSamples:\n",
    "                emailPath=os.path.join(datasetPath,emailName)\n",
    "                with codecs.open(emailPath,\"r\",'utf8') as file:\n",
    "                    count=0\n",
    "                    data = json.load(file)\n",
    "                    for elements in data[\"denotations\"]:\n",
    "                        if elements[\"type\"] in contentType:\n",
    "                            text=elements[\"text\"].lower()\n",
    "                            text=re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''',\"\", text)\n",
    "                            text=re.sub(r\"\\S*@\\S*\\s?\",\"\", text)\n",
    "                            text=re.sub(r\"[^A-Za-z0-9\\n]+\",\" \", text)\n",
    "                            text=text.split(\"\\n\")\n",
    "                            text=[(i, x) for i, x in enumerate(text, 1)]\n",
    "                            temp=text[-1][0]\n",
    "                            text=[x for x in text if len(x[1])>1]\n",
    "                            \n",
    "                            #Statistics about the structure of the email \n",
    "                            for x in text:\n",
    "                                if elements[\"type\"]==\"Body\": \n",
    "                                    textStatistics[\"Body\"].append((count+x[0],len(x[1])))\n",
    "                                elif elements[\"type\"]==\"Body/Intro\": \n",
    "                                    textStatistics[\"Body/Intro\"].append((count+x[0],len(x[1])))\n",
    "                                elif elements[\"type\"]==\"Body/Outro\": \n",
    "                                    textStatistics[\"Body/Outro\"].append((count+x[0],len(x[1])))\n",
    "                                elif elements[\"type\"]==\"Body/Signature\": \n",
    "                                    textStatistics[\"Body/Signature\"].append((count+x[0],len(x[1])))    \n",
    "                            \n",
    "                            #Write training samples to a file\n",
    "                            text=[emailName+\" @@@ \"+elements[\"type\"]+\" @@@ \"+str(count+x[0]) +\" @@@ \"+str(len(x[1]))\n",
    "                                  +\" @@@ \"+x[1] for x in text]\n",
    "                            count=count+temp\n",
    "                            trainingSamples.extend(text)\n",
    "        \n",
    "        print(\"Average 'Body' length: \"+str(np.average([x[1] for x in textStatistics[\"Body\"]])))\n",
    "        print(\"Average 'Body' position: \"+str(np.average([x[0] for x in textStatistics[\"Body\"]])))\n",
    "        print(\"Average 'Body/Intro' length: \"+str(np.average([x[1] for x in textStatistics[\"Body/Intro\"]])))\n",
    "        print(\"Average 'Body/Intro' position: \"+str(np.average([x[0] for x in textStatistics[\"Body/Intro\"]])))\n",
    "        print(\"Average 'Body/Outro' length: \"+str(np.average([x[1] for x in textStatistics[\"Body/Outro\"]])))\n",
    "        print(\"Average 'Body/Outro' position: \"+str(np.average([x[0] for x in textStatistics[\"Body/Outro\"]])))\n",
    "        print(\"Average 'Body/Signature' length: \"+str(np.average([x[1] for x in textStatistics[\"Body/Signature\"]])))\n",
    "        print(\"Average 'Body/Signature' position: \"+str(np.average([x[0] for x in textStatistics[\"Body/Signature\"]])))\n",
    "        \n",
    "        with codecs.open(filePath, \"w\",'utf8') as file:    \n",
    "            [file.write(x+\"\\n\") for x in trainingSamples]\n",
    "    \n",
    "    else: print (\"Training document already exist\")\n",
    "        \n",
    "    if not (os.path.isfile(filePath2)): \n",
    "        \n",
    "        print(\"Create test document\")\n",
    "        testSamples=[]\n",
    "        \n",
    "        textStatistics={\"Body\":[], \"Body/Intro\":[], \"Body/Outro\":[], \"Body/Signature\":[]}\n",
    "        \n",
    "        dataSetsTest=[\"enronTest\",\"apacheTest\"]\n",
    "        for dataSetName in dataSetsTest:\n",
    "            datasetPath=os.path.join(datasetsPath,dataSetName)\n",
    "            emailSamples = [f for f in listdir(datasetPath) if f.endswith(\".ann\")]\n",
    "            for emailName in emailSamples:\n",
    "                emailPath=os.path.join(datasetPath,emailName)\n",
    "                with codecs.open(emailPath,\"r\",'utf8') as file:\n",
    "                    count=0\n",
    "                    data = json.load(file)\n",
    "                    for elements in data[\"denotations\"]:\n",
    "                        if elements[\"type\"] in contentType:\n",
    "                            text=elements[\"text\"].lower()\n",
    "                            text=re.sub(r'''(?i)\\b((?:https?://|www\\d{0,3}[.]|[a-z0-9.\\-]+[.][a-z]{2,4}/)(?:[^\\s()<>]+|\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\))+(?:\\(([^\\s()<>]+|(\\([^\\s()<>]+\\)))*\\)|[^\\s`!()\\[\\]{};:'\".,<>?«»“”‘’]))''',\"\", text)\n",
    "                            text=re.sub(r\"\\S*@\\S*\\s?\",\"\", text)\n",
    "                            text=re.sub(r\"[^A-Za-z0-9\\n]+\",\" \", text)\n",
    "                            text=text.split(\"\\n\")\n",
    "                            text=[(i, x) for i, x in enumerate(text, 1)]\n",
    "                            temp=text[-1][0]\n",
    "                            text=[x for x in text if len(x[1])>1]\n",
    "                            text=[emailName+\" @@@ \"+elements[\"type\"]+\" @@@ \"+str(count+x[0]) +\" @@@ \"+str(len(x[1]))\n",
    "                                  +\" @@@ \"+x[1] for x in text]\n",
    "                            count=count+temp\n",
    "                            testSamples.extend(text)\n",
    "    \n",
    "        with codecs.open(filePath2, \"w\",'utf8') as file:    \n",
    "            [file.write(x+\"\\n\") for x in testSamples]    \n",
    "    \n",
    "    else: print (\"Test document already exist\")\n",
    "    \n",
    "except IOError as e:\n",
    "    print (\"Could not read file\")\n",
    "    print(traceback.format_exc())\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print (\"Unexpected error\")\n",
    "    print(traceback.format_exc())\n",
    "    print(e)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shark\\Anaconda3\\lib\\site-packages\\smart_open\\smart_open_lib.py:398: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
      "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
     ]
    }
   ],
   "source": [
    "from gensim.models.keyedvectors import KeyedVectors\n",
    "model2 = KeyedVectors.load_word2vec_format(\"GoogleNews-vectors-negative300.bin.gz\", binary=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3\\. Extract character ngrams from project emails (JPL, Enron, APWG, etc.) in order to create distinct embedding models. These models will be used for generating training and test vectors associated to Quagga samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: 'dataset' exists\n",
      "Directory: 'experiments' exists\n",
      "Document: 'friendFoeTrainingCharacterNgramSize-1.txt' already exist\n",
      "Creating word embedding model of size: 600\n"
     ]
    }
   ],
   "source": [
    "#Word embeddings functions to create word vectors\n",
    "import gensim \n",
    "#Encoding functions for opening files in the correct format\n",
    "import codecs\n",
    "import errno\n",
    "#Operating system functions for interacting with folders and files\n",
    "import os\n",
    "from os import listdir\n",
    "import sys\n",
    "import traceback\n",
    "#Mathematical functions to handle vectors\n",
    "import numpy as np\n",
    "#object-serializing functions\n",
    "import pickle\n",
    "#Calendar functions for timestamp\n",
    "import datetime\n",
    "import time\n",
    "#Text maipulation functions (eliminate certain words for instance)\n",
    "import re\n",
    "\n",
    "friendFoeTrainingTexts=[]\n",
    "#Check if the notebook path is already loaded\n",
    "try:  \n",
    "    noteBookPath\n",
    "except NameError:\n",
    "    print (\"NotebookPath variable dont exist, applying default one\")\n",
    "    noteBookPath= os.getcwd()\n",
    "    pass\n",
    "\n",
    "\n",
    "#Check if dataset path exist\n",
    "datasetFolder=\"dataset\"\n",
    "try:\n",
    "    datasetsPath=os.path.join(noteBookPath,datasetFolder) \n",
    "    if not os.path.isdir(datasetsPath): raise Exception(\"'Dataset' folder dont exist\")\n",
    "    else: \n",
    "        print (\"Directory: '\"+ datasetFolder+\"' exists\")\n",
    "        pass\n",
    "except SystemExit as e:\n",
    "    print(e)\n",
    "\n",
    "#Create experiments folder if not exists\n",
    "dirName=\"experiments\"\n",
    "try:\n",
    "    os.mkdir(os.path.join(noteBookPath,dirName) )\n",
    "    print (\"Directory: '\"+dirName+\"' Created\") \n",
    "except OSError as e:\n",
    "    if e.errno == errno.EEXIST:\n",
    "        print (\"Directory: '\"+ dirName+\"' exists\")\n",
    "        pass\n",
    "    else:\n",
    "        raise \n",
    "except:\n",
    "    print (\"Unexpected error\")\n",
    "    pass  \n",
    "\n",
    "#Check if the experiments folder path exist\n",
    "try:  \n",
    "    experimentsPath\n",
    "except NameError:\n",
    "    print (\"datasetPath variable dont exist, applying default one\")\n",
    "    experimentsPath=os.path.join(noteBookPath,dirName)\n",
    "    pass\n",
    "\n",
    "#Python Script\n",
    "try:\n",
    "    \n",
    "    #Character ngram size\n",
    "    characterNgram=1\n",
    "    #Character embedding size vectors\n",
    "    featureNumbers=[600]\n",
    "    \n",
    "    document = \"friendFoeTraining.txt\"\n",
    "    filePath = os.path.join(experimentsPath,document)\n",
    "    \n",
    "    document2 = \"friendFoeTrainingCharacterNgramSize-\"+str(characterNgram)+\".txt\"\n",
    "    filePath2 = os.path.join(experimentsPath,document2)\n",
    "    \n",
    "    if (os.path.isfile(filePath)):\n",
    "        \n",
    "         if not (os.path.isfile(filePath2)): \n",
    "            \n",
    "            print(\"Extracting character ngrams of size: \"+str(characterNgram))\n",
    "            friendFoeTraining=[]\n",
    "            with codecs.open(filePath,\"r\",'ISO-8859-1') as file:\n",
    "                for line in file:\n",
    "                    elements=line.split(\" @@@ \")\n",
    "                    #Preprocess the text samples\n",
    "                    elements[1]=elements[1].replace(\"#\", \"\")\n",
    "                       #Eliminate URls\n",
    "                    elements[1]=re.sub(r\"http\\S+\",\"\", elements[1])\n",
    "                       #Eliminate usernames (which don't give any additional information for this analysis)\n",
    "                    elements[1]=re.sub(r\"@[^\\s]+\",\"\",elements[1])\n",
    "                    #text=text.replace(\" \", \"\")\n",
    "                    #Sseparate words in character ngrams for creating the embedding model\n",
    "                    #text=\" \".join([text[i:i+characterNgram] for i in range(len(text)-characterNgram+1)])\n",
    "                    friendFoeTraining.append(elements[0] + \" @@@ \" + elements[1])\n",
    "                    friendFoeTrainingTexts.append(elements[1])\n",
    "                    \n",
    "                \n",
    "            with codecs.open(filePath2, \"w\",'ISO-8859-1') as file:    \n",
    "                #[file.write(x[0]+\" @@@ \"+x[1]+\"\\n\") for x in friendFoeTraining]\n",
    "                [file.write(text) for text in friendFoeTraining]\n",
    "                \n",
    "                \n",
    "                \n",
    "            \n",
    "            print(friendFoeTrainingTexts[0])\n",
    "            for number in featureNumbers:\n",
    "            \n",
    "                document3 = \"ngram-\"+str(characterNgram)+\"-EmbeddingModelSize-\"+str(number)\n",
    "                filePath3 = os.path.join(experimentsPath,document3)\n",
    "                \n",
    "                if not (os.path.isfile(filePath3)): \n",
    "                    \n",
    "                    print(\"Creating word embedding model of size: \"+str(number))\n",
    "                    #Traing wordEmbedding model\n",
    "                    model = gensim.models.Word2Vec(friendFoeTrainingTexts,size=number,window=10,min_count=2,workers=10)\n",
    "                    model.train(friendFoeTrainingTexts, total_examples=len(friendFoeTrainingTexts), epochs=10)\n",
    "                    #Serialize word-embedding object\n",
    "                    with open(filePath3, \"wb\") as file:\n",
    "                        pickle.dump(model, file)\n",
    "                else: print (\"Model: '\"+document3+\"' already exist\")        \n",
    "                        \n",
    "         else: \n",
    "            \n",
    "            print (\"Document: '\"+document2+\"' already exist\")\n",
    "            \n",
    "            with codecs.open(filePath2,\"r\",'ISO-8859-1') as file:\n",
    "                friendFoeTrainingTexts=[(line.split(\" @@@ \")[1]).split(\" \") for line in file]\n",
    "            \n",
    "            for number in featureNumbers:\n",
    "            \n",
    "                document3 = \"ngram-\"+str(characterNgram)+\"-EmbeddingModelSize-\"+str(number)\n",
    "                filePath3 = os.path.join(experimentsPath,document3)\n",
    "                \n",
    "                \n",
    "                if not (os.path.isfile(filePath3)): \n",
    "                    \n",
    "                    print(\"Creating word embedding model of size: \"+str(number))\n",
    "                    #Traing wordEmbedding model\n",
    "                    model = gensim.models.Word2Vec(friendFoeTrainingTexts,size=number,window=10,min_count=2,workers=10)\n",
    "                    model.train(friendFoeTrainingTexts, total_examples=len(friendFoeTrainingTexts), epochs=10)\n",
    "                    #Serialize word-embedding object\n",
    "                    with open(filePath3, \"wb\") as file:\n",
    "                        pickle.dump(model, file)\n",
    "                else: print (\"Model: '\"+document3+\"' already exist\") \n",
    "                 \n",
    "    else: print (\"Friend/foe training document dont exist\")\n",
    "         \n",
    "except IOError as e:\n",
    "    print (\"Could not read file\")\n",
    "    print(traceback.format_exc())\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print (\"Unexpected error\")\n",
    "    print(traceback.format_exc())\n",
    "    print(e)      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4\\. Create training and test vectors for structural dataset considering the previously created embedding models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: 'dataset' exists\n",
      "Directory: 'experiments' exists\n",
      "Create training vectors of size: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shark\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:123: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "C:\\Users\\Shark\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:124: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Create test vectors of size: 300\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shark\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:187: DeprecationWarning: Call to deprecated `__contains__` (Method will be removed in 4.0.0, use self.wv.__contains__() instead).\n",
      "C:\\Users\\Shark\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:188: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
     ]
    }
   ],
   "source": [
    "#Word embeddings functions to create word vectors\n",
    "import gensim \n",
    "#Encoding functions for opening files in the correct format\n",
    "import codecs\n",
    "import errno\n",
    "#Operating system functions for interacting with folders and files\n",
    "import os\n",
    "from os import listdir\n",
    "import sys\n",
    "import traceback\n",
    "#Mathematical functions to handle vectors\n",
    "import numpy as np\n",
    "#object-serializing functions\n",
    "import pickle\n",
    "#Calendar functions for timestamp\n",
    "import datetime\n",
    "import time\n",
    "#Text maipulation functions (eliminate certain words for instance)\n",
    "import re\n",
    "\n",
    "#Check if the notebook path is already loaded\n",
    "try:  \n",
    "    noteBookPath\n",
    "except NameError:\n",
    "    print (\"NotebookPath variable dont exist, applying default one\")\n",
    "    noteBookPath= os.getcwd()\n",
    "    pass\n",
    "\n",
    "\n",
    "#Check if dataset path exist\n",
    "datasetFolder=\"dataset\"\n",
    "try:\n",
    "    datasetsPath=os.path.join(noteBookPath,datasetFolder) \n",
    "    if not os.path.isdir(datasetsPath): raise Exception(\"'Dataset' folder dont exist\")\n",
    "    else: \n",
    "        print (\"Directory: '\"+ datasetFolder+\"' exists\")\n",
    "        pass\n",
    "except SystemExit as e:\n",
    "    print(e)\n",
    "\n",
    "#Create experiments folder if not exists\n",
    "dirName=\"experiments\"\n",
    "try:\n",
    "    os.mkdir(os.path.join(noteBookPath,dirName) )\n",
    "    print (\"Directory: '\"+dirName+\"' Created\") \n",
    "except OSError as e:\n",
    "    if e.errno == errno.EEXIST:\n",
    "        print (\"Directory: '\"+ dirName+\"' exists\")\n",
    "        pass\n",
    "    else:\n",
    "        raise \n",
    "except:\n",
    "    print (\"Unexpected error\")\n",
    "    pass  \n",
    "\n",
    "#Check if the experiments folder path exist\n",
    "try:  \n",
    "    experimentsPath\n",
    "except NameError:\n",
    "    print (\"datasetPath variable dont exist, applying default one\")\n",
    "    experimentsPath=os.path.join(noteBookPath,dirName)\n",
    "    pass\n",
    "\n",
    "#Python Script\n",
    "try:\n",
    "    \n",
    "    document = \"structuralAnaysisTraining.txt\"\n",
    "    filePath = os.path.join(experimentsPath,document)\n",
    "\n",
    "    document2 = \"structuralAnaysisTest.txt\"\n",
    "    filePath2 = os.path.join(experimentsPath,document2)\n",
    "    \n",
    "    #Character ngram size\n",
    "    characterNgram=1\n",
    "    #Character embedding size vectors\n",
    "    featureNumbers=[300]\n",
    "    \n",
    "    #Training vectors creation (if needed)\n",
    "    if os.path.isfile(filePath):\n",
    "        \n",
    "        trainingTexts=[]\n",
    "        labels=[]\n",
    "        trainingLabels=[]\n",
    "        with codecs.open(filePath, \"r\", \"utf8\") as file: \n",
    "            for line in file:\n",
    "                try:\n",
    "                    elements=line.split(\" @@@ \")\n",
    "                    labels.append(elements[1])\n",
    "                    #text=elements[4].rstrip()\n",
    "                    trainingTexts.append((elements[4].rstrip()).split(\" \"))\n",
    "                except IndexError: pass\n",
    "                \n",
    "                \n",
    "        for label in labels:\n",
    "            if label==\"Body\":         trainingLabels.append([\"1\", \"0\", \"0\", \"0\"])\n",
    "            elif label==\"Body/Intro\": trainingLabels.append([\"0\", \"1\", \"0\", \"0\"])\n",
    "            elif label==\"Body/Outro\": trainingLabels.append([\"0\", \"0\", \"1\", \"0\"]) \n",
    "            else:                     trainingLabels.append([\"0\", \"0\", \"0\", \"1\"])\n",
    "        \n",
    "        \n",
    "        #Create character embeddings for training emails\n",
    "        for number in featureNumbers:\n",
    "            \n",
    "            print(\"Create training vectors of size: \"+str(number))\n",
    "            \n",
    "            document3 = \"Ngram-\"+str(characterNgram)+\"-EmbeddingModelSize-\"+str(number)\n",
    "            filePath3 = os.path.join(experimentsPath,document3)\n",
    "            \n",
    "            document4 = \"ngram-\"+str(characterNgram)+\"TrainingVectorsSize-\"+str(number)+\".txt\"\n",
    "            filePath4 = os.path.join(experimentsPath,document4)\n",
    "        \n",
    "            if (os.path.isfile(filePath3)) and not os.path.isfile(filePath4):\n",
    "                \n",
    "                with open(filePath3, \"rb\") as file: \n",
    "                    model= pickle.load(file,encoding=\"bytes\")\n",
    "                \n",
    "                #Create training vectors   \n",
    "                trainingVectors=[]\n",
    "                for text in trainingTexts:\n",
    "                    wordVectors=[]\n",
    "                    for word in text:\n",
    "                        try:\n",
    "                            if word in model:\n",
    "                                wordVectors.append(model[word])\n",
    "                            elif word in model2:\n",
    "                                wordVectors.append(model2[word])\n",
    "                        except:\n",
    "                            pass\n",
    "                    if len(wordVectors)>=1:    \n",
    "                          wordVectors=np.array(wordVectors)    \n",
    "                          trainingVectors.append((wordVectors.mean(axis=0)).tolist())\n",
    "                    else: trainingVectors.append([0 for x in range(number)])\n",
    "                        \n",
    "                #Save train vectors in a text file\n",
    "                with codecs.open(filePath4, \"w\", 'ISO-8859-1') as file:   \n",
    "                    for vector,label in zip(trainingVectors,trainingLabels):\n",
    "                        file.write((\",\".join(label))+\",\"+(\",\".join([str(x) for x in vector]))+\"\\n\")\n",
    "                            \n",
    "            else: print (\"Character embedding model dont exist or training vectors already created\")\n",
    "                    \n",
    "    else: print (\"Training document: \"+document+\" dont exist\")\n",
    "        \n",
    "        \n",
    "    #Test vectors creation (if needed)\n",
    "    if os.path.isfile(filePath2):\n",
    "                       \n",
    "        testTexts=[]\n",
    "        labels=[]\n",
    "        testLabels=[]\n",
    "        with codecs.open(filePath2, \"r\", \"utf8\") as file: \n",
    "            for line in file:\n",
    "                try:\n",
    "                    elements=line.split(\" @@@ \")\n",
    "                    labels.append(elements[1])\n",
    "                    #text=elements[1].rstrip()\n",
    "                    testTexts.append((elements[4].rstrip()).split(\" \"))\n",
    "                except IndexError: pass\n",
    "                 \n",
    "        for label in labels:\n",
    "            if label==\"Body\":         testLabels.append([\"1\", \"0\", \"0\", \"0\"])\n",
    "            elif label==\"Body/Intro\": testLabels.append([\"0\", \"1\", \"0\", \"0\"])\n",
    "            elif label==\"Body/Outro\": testLabels.append([\"0\", \"0\", \"1\", \"0\"]) \n",
    "            else:                     testLabels.append([\"0\", \"0\", \"0\", \"1\"]) \n",
    "                             \n",
    "        #Create character embeddings for test emails\n",
    "        for number in featureNumbers:\n",
    "            \n",
    "            print(\"Create test vectors of size: \"+str(number))\n",
    "            \n",
    "            document3 = \"Ngram-\"+str(characterNgram)+\"-EmbeddingModelSize-\"+str(number)\n",
    "            filePath3 = os.path.join(experimentsPath,document3)\n",
    "\n",
    "            document5 = \"ngram-\"+str(characterNgram)+\"TestVectorsSize-\"+str(number)+\".txt\"\n",
    "            filePath5 = os.path.join(experimentsPath,document5)\n",
    "        \n",
    "            if (os.path.isfile(filePath3)) and not os.path.isfile(filePath5):\n",
    "                \n",
    "                with open(filePath3, \"rb\") as file: \n",
    "                    model= pickle.load(file,encoding=\"bytes\")\n",
    "                    \n",
    "                #Create test vectors   \n",
    "                testVectors=[]\n",
    "                for text in testTexts:\n",
    "                    testVector=[]\n",
    "                    for word in text:\n",
    "                        try:\n",
    "                            if word in model:\n",
    "                                testVector.append(model[word])\n",
    "                            elif word in model2:\n",
    "                                testVector.append(model2[word])\n",
    "                        except:\n",
    "                            pass\n",
    "                    if len(testVector)>=1:    \n",
    "                          testVector=np.array(testVector)    \n",
    "                          testVectors.append((testVector.mean(axis=0)).tolist())\n",
    "                    else: testVectors.append([0 for x in range(number)])\n",
    "                        \n",
    "                #Save test vectors in a text file\n",
    "                with codecs.open(filePath5, \"w\", 'ISO-8859-1') as file:   \n",
    "                    for vector,label in zip(testVectors,testLabels):\n",
    "                        file.write((\",\".join(label))+\",\"+(\",\".join([str(x) for x in vector]))+\"\\n\")               \n",
    "            \n",
    "            else: print (\"Character embedding model dont exist or test vectors already created\")\n",
    "                 \n",
    "    else: print (\"Test document: \"+document2+\" dont exist\")      \n",
    "\n",
    "except IOError as e:\n",
    "    print (\"Could not read file\")\n",
    "    print(traceback.format_exc())\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print (\"Unexpected error\")\n",
    "    print(traceback.format_exc())\n",
    "    print(e)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5\\. Create and test a Neural Network (Back propagation approach) using the training and test vectors previously created."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: 'dataset' exists\n",
      "Directory: 'experiments' exists\n",
      "Character embeddings experiments using vectors of size: 300\n",
      "300,50-40-30-20-10,3,20,0.9423428491070173,0.8443389055898961\n",
      "300,50-40-30-20-10,3,25,0.93362396287442,0.8200243920546941\n",
      "300,50-40-30-20-10,3,30,0.9391084235691183,0.8098930963042977\n",
      "300,50-40-30-20-10,3,35,0.9412178315286176,0.8062301051709501\n",
      "300,50-40-30-20-10,3,40,0.9350302348474195,0.8212939565546891\n",
      "300,50-40-30-20-10,3,45,0.9412178315286176,0.8273859609312932\n",
      "300,50-40-30-20-10,3,50,0.9354521164393194,0.815714891083637\n",
      "300,50-40-30-20-10,3,55,0.9422022219097174,0.8366257689774751\n",
      "300,50-40-30-20-10,3,60,0.9427647306989172,0.8415925747237347\n",
      "300,50-40-30-20-10,3,65,0.9427647306989172,0.8421136139249139\n",
      "300,50-40-30-20-10,3,70,0.9382646603853185,0.8352433982410151\n",
      "300,50-40-30-20-10,3,75,0.9326395724933202,0.8304500898537462\n",
      "300,50-40-30-20-10,3,80,0.9319364365068205,0.8224710537345196\n",
      "300,50-40-30-20-10,3,85,0.9392490507664182,0.826756126534209\n",
      "300,50-40-30-20-10,3,90,0.9419209675151174,0.8357146346805716\n",
      "300,50-40-30-20-10,3,95,0.9389677963718183,0.8272680304068832\n",
      "300,50-40-30-20-10,3,100,0.9357333708339193,0.826548342658486\n",
      "300,50-40-30-20-10,3,105,0.9409365771340177,0.8340229647644865\n",
      "300,50-40-30-20-10,4,20,0.9322176909014204,0.8182437769246979\n",
      "300,50-40-30-20-10,4,25,0.9354521164393194,0.8237998222937678\n",
      "300,50-40-30-20-10,4,30,0.9377021515961187,0.824111539359064\n",
      "300,50-40-30-20-10,4,35,0.9277176205878217,0.8175459954503053\n",
      "300,50-40-30-20-10,4,40,0.93334270847982,0.82434541963532\n",
      "300,50-40-30-20-10,4,45,0.9364365068204191,0.8225469967589706\n",
      "300,50-40-30-20-10,4,50,0.9322176909014204,0.8221931457121467\n",
      "300,50-40-30-20-10,4,55,0.9284207565743214,0.8210578906283867\n",
      "300,50-40-30-20-10,4,60,0.9317958093095204,0.8116276058702029\n",
      "300,50-40-30-20-10,4,65,0.9379834059907186,0.8226876386546111\n",
      "300,50-40-30-20-10,4,70,0.9344677260582197,0.8222823887981096\n",
      "300,50-40-30-20-10,4,75,0.9374208972015188,0.8269780127559584\n",
      "300,50-40-30-20-10,4,80,0.9327801996906202,0.8182329593392638\n",
      "300,50-40-30-20-10,4,85,0.9403740683448178,0.826512866531732\n",
      "300,50-40-30-20-10,4,90,0.9312333005203206,0.8167704372570492\n",
      "300,50-40-30-20-10,4,95,0.936577134017719,0.8255435304048291\n",
      "300,50-40-30-20-10,4,100,0.9357333708339193,0.8269144151973258\n",
      "300,50-40-30-20-10,4,105,0.930248910139221,0.8175530751453088\n",
      "300,50-40-30-20-10,5,20,0.9324989452960203,0.8138001378988097\n",
      "300,50-40-30-20-10,5,25,0.9275769933905217,0.8145078463784582\n",
      "300,50-40-30-20-10,5,30,0.926592603009422,0.8051088383364863\n",
      "300,50-40-30-20-10,5,35,0.929967655744621,0.8226791971303998\n",
      "300,50-40-30-20-10,5,40,0.93362396287442,0.8145441272020782\n",
      "300,50-40-30-20-10,5,45,0.9343270988609197,0.8228595779740653\n",
      "300,50-40-30-20-10,5,50,0.9296864013500211,0.8108767955671348\n",
      "300,50-40-30-20-10,5,55,0.9378427787934186,0.8230545136342474\n",
      "300,50-40-30-20-10,5,60,0.9309520461257207,0.8085203438846981\n",
      "300,50-40-30-20-10,5,65,0.9278582477851216,0.807079396676357\n",
      "300,50-40-30-20-10,5,70,0.93334270847982,0.8115646284921684\n",
      "300,50-40-30-20-10,5,75,0.923639431866123,0.8068303396707028\n",
      "300,50-40-30-20-10,5,80,0.9351708620447194,0.8153863916856628\n",
      "300,50-40-30-20-10,5,85,0.9343270988609197,0.8146986930873773\n",
      "300,50-40-30-20-10,5,90,0.9246238222472226,0.8019993063046028\n",
      "300,50-40-30-20-10,5,95,0.9326395724933202,0.8089260760544166\n",
      "300,50-40-30-20-10,5,100,0.929967655744621,0.8054025509722514\n",
      "300,50-40-30-20-10,5,105,0.9301082829419209,0.8087241674017404\n",
      "300,50-40-30-20-10,6,20,0.9334833356771199,0.80483840637605\n",
      "300,50-40-30-20-10,6,25,0.9281395021797215,0.7985233708123775\n",
      "300,50-40-30-20-10,6,30,0.9347489804528196,0.8093404708097616\n",
      "300,50-40-30-20-10,6,35,0.930248910139221,0.8068490331582341\n",
      "300,50-40-30-20-10,6,40,0.9327801996906202,0.8062876936875427\n",
      "300,50-40-30-20-10,6,45,0.9279988749824216,0.7997451564864614\n",
      "300,50-40-30-20-10,6,50,0.9316551821122205,0.8057543490679028\n",
      "300,50-40-30-20-10,6,55,0.9254675854310224,0.8001521282713372\n",
      "300,50-40-30-20-10,6,60,0.9313739277176206,0.8037398211033384\n",
      "300,50-40-30-20-10,6,65,0.9330614540852201,0.8052520497195973\n",
      "300,50-40-30-20-10,6,70,0.9358739980312193,0.812511712268324\n",
      "300,50-40-30-20-10,6,75,0.9258894670229222,0.802340208848659\n",
      "300,50-40-30-20-10,6,80,0.930248910139221,0.8053013259826676\n",
      "300,50-40-30-20-10,6,85,0.9267332302067219,0.8005546408274111\n",
      "300,50-40-30-20-10,6,90,0.9322176909014204,0.8070712629127884\n",
      "300,50-40-30-20-10,6,95,0.930248910139221,0.7879449705833781\n",
      "300,50-40-30-20-10,6,100,0.9354521164393194,0.8083948316564724\n",
      "300,50-40-30-20-10,6,105,0.9351708620447194,0.8090989633460451\n",
      "300,50-40-30-20-10,7,20,0.9322176909014204,0.799485290586284\n",
      "300,50-40-30-20-10,7,25,0.9358739980312193,0.8029307342457622\n",
      "300,50-40-30-20-10,7,30,0.9344677260582197,0.8053350334801829\n",
      "300,50-40-30-20-10,7,35,0.9306707917311208,0.8033398209197511\n",
      "300,50-40-30-20-10,7,40,0.930248910139221,0.7965233096279661\n",
      "300,50-40-30-20-10,7,45,0.9317958093095204,0.789106551746448\n",
      "300,50-40-30-20-10,7,50,0.9323583180987203,0.7982788992145572\n",
      "300,50-40-30-20-10,7,55,0.9361552524258192,0.809614498410573\n",
      "300,50-40-30-20-10,7,60,0.9308114189284208,0.8008028588867141\n",
      "300,50-40-30-20-10,7,65,0.9306707917311208,0.7974312033972147\n",
      "300,50-40-30-20-10,7,70,0.9327801996906202,0.8026602068564545\n",
      "300,50-40-30-20-10,7,75,0.9310926733230207,0.8056193447059558\n",
      "300,50-40-30-20-10,7,80,0.9312333005203206,0.7942674445398641\n",
      "300,50-40-30-20-10,7,85,0.9326395724933202,0.8008849314859855\n",
      "300,50-40-30-20-10,7,90,0.9357333708339193,0.8070337086965699\n",
      "300,50-40-30-20-10,7,95,0.9344677260582197,0.8055055771612101\n",
      "300,50-40-30-20-10,7,100,0.9334833356771199,0.8121731984883905\n",
      "300,50-40-30-20-10,7,105,0.9346083532555196,0.8158495366575075\n",
      "300,50-40-30-20-10,8,20,0.9353114892420195,0.8121607907945162\n",
      "300,50-40-30-20-10,8,25,0.9368583884123189,0.8116683876583334\n",
      "300,50-40-30-20-10,8,30,0.9319364365068205,0.7850281404240013\n",
      "300,50-40-30-20-10,8,35,0.9391084235691183,0.813249855546927\n",
      "300,50-40-30-20-10,8,40,0.9355927436366194,0.8027104649184068\n",
      "300,50-40-30-20-10,8,45,0.93362396287442,0.798855530001771\n",
      "300,50-40-30-20-10,8,50,0.9354521164393194,0.800136624566243\n",
      "300,50-40-30-20-10,8,55,0.9327801996906202,0.7909241154911424\n",
      "300,50-40-30-20-10,8,60,0.9350302348474195,0.7983099652059512\n",
      "300,50-40-30-20-10,8,65,0.93320208128252,0.8021247319174781\n",
      "300,50-40-30-20-10,8,70,0.93362396287442,0.7968492604229563\n",
      "300,50-40-30-20-10,8,75,0.926451975812122,0.7847091156059922\n",
      "300,50-40-30-20-10,8,80,0.93334270847982,0.7935003519255436\n",
      "300,50-40-30-20-10,8,85,0.9326395724933202,0.7787567666438648\n",
      "300,50-40-30-20-10,8,90,0.9301082829419209,0.7851293438020748\n",
      "300,50-40-30-20-10,8,95,0.9323583180987203,0.792740890797672\n",
      "300,50-40-30-20-10,8,100,0.9324989452960203,0.7885996415020436\n",
      "300,50-40-30-20-10,8,105,0.9292645197581212,0.7776273710273477\n",
      "300,50-40-30-20-10,9,20,0.9310926733230207,0.785665511527548\n",
      "300,50-40-30-20-10,9,25,0.93320208128252,0.7861104122175173\n",
      "300,50-40-30-20-10,9,30,0.9324989452960203,0.7882260061084326\n",
      "300,50-40-30-20-10,9,35,0.9313739277176206,0.7835475055400072\n",
      "300,50-40-30-20-10,9,40,0.9330614540852201,0.795951045393745\n",
      "300,50-40-30-20-10,9,45,0.9294051469554212,0.7768012631671195\n",
      "300,50-40-30-20-10,9,50,0.93320208128252,0.7940743614346468\n",
      "300,50-40-30-20-10,9,55,0.9295457741527211,0.7889013027940965\n",
      "300,50-40-30-20-10,9,60,0.9319364365068205,0.7862783985981375\n",
      "300,50-40-30-20-10,9,65,0.93320208128252,0.7898034424065875\n",
      "300,50-40-30-20-10,9,70,0.9341864716636198,0.7937928872853193\n",
      "300,50-40-30-20-10,9,75,0.9324989452960203,0.7847035441894193\n",
      "300,50-40-30-20-10,9,80,0.9348896076501195,0.7957529184747933\n",
      "300,50-40-30-20-10,9,85,0.9270144846013219,0.7951328455195638\n",
      "300,50-40-30-20-10,9,90,0.9330614540852201,0.7919626389298967\n",
      "300,50-40-30-20-10,9,95,0.929827028547321,0.7889151041331322\n",
      "300,50-40-30-20-10,9,100,0.9310926733230207,0.7978006795294704\n",
      "300,50-40-30-20-10,9,105,0.9306707917311208,0.7856152515344504\n",
      "300,50-25-10,3,20,0.9434678666854169,0.8379461857101558\n",
      "300,50-25-10,3,25,0.9403740683448178,0.8342923970016279\n",
      "300,50-25-10,3,30,0.9427647306989172,0.8318846479203841\n",
      "300,50-25-10,3,35,0.9437491210800169,0.8436605603165828\n",
      "300,50-25-10,3,40,0.9437491210800169,0.8327679806821756\n",
      "300,50-25-10,3,45,0.9440303754746168,0.8351693136216695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300,50-25-10,3,50,0.9413584587259176,0.8362502335602207\n",
      "300,50-25-10,3,55,0.9426241035016172,0.8351175645686038\n",
      "300,50-25-10,3,60,0.9424834763043173,0.8337038515871136\n",
      "300,50-25-10,3,65,0.940233441147518,0.8325002696922925\n",
      "300,50-25-10,3,70,0.9409365771340177,0.8335762343185461\n",
      "300,50-25-10,3,75,0.9395303051610181,0.831413898053802\n",
      "300,50-25-10,3,80,0.9417803403178174,0.8340818275474676\n",
      "300,50-25-10,3,85,0.9362958796231191,0.8185536400473025\n",
      "300,50-25-10,3,90,0.939811559555618,0.8358787187801443\n",
      "300,50-25-10,3,95,0.9403740683448178,0.8340120943898918\n",
      "300,50-25-10,3,100,0.9413584587259176,0.8316143843113881\n",
      "300,50-25-10,3,105,0.940233441147518,0.8336866593415088\n",
      "300,50-25-10,4,20,0.9351708620447194,0.8227053860575936\n",
      "300,50-25-10,4,25,0.9320770637041204,0.8160966422523175\n",
      "300,50-25-10,4,30,0.9381240331880185,0.8171731698478054\n",
      "300,50-25-10,4,35,0.9416397131205175,0.824717723849916\n",
      "300,50-25-10,4,40,0.9396709323583181,0.8138847220959397\n",
      "300,50-25-10,4,45,0.9382646603853185,0.805146580554606\n",
      "300,50-25-10,4,50,0.9381240331880185,0.8130991829305749\n",
      "300,50-25-10,4,55,0.936577134017719,0.8082202718171084\n",
      "300,50-25-10,4,60,0.9385459147799184,0.816185707182937\n",
      "300,50-25-10,4,65,0.9351708620447194,0.8040494950900566\n",
      "300,50-25-10,4,70,0.9353114892420195,0.8108256257681606\n",
      "300,50-25-10,4,75,0.9343270988609197,0.7961225628743233\n",
      "300,50-25-10,4,80,0.9367177612150189,0.8037284720515308\n",
      "300,50-25-10,4,85,0.9282801293770215,0.8001145424099262\n",
      "300,50-25-10,4,90,0.9357333708339193,0.8070884183139592\n",
      "300,50-25-10,4,95,0.9347489804528196,0.800958875876809\n",
      "300,50-25-10,4,100,0.9353114892420195,0.8053943581722321\n",
      "300,50-25-10,4,105,0.9355927436366194,0.8082066881024389\n",
      "300,50-25-10,5,20,0.9355927436366194,0.8048035149774503\n",
      "300,50-25-10,5,25,0.9340458444663198,0.8011376134235381\n",
      "300,50-25-10,5,30,0.936577134017719,0.8048441133343448\n",
      "300,50-25-10,5,35,0.9362958796231191,0.8022158309939615\n",
      "300,50-25-10,5,40,0.9334833356771199,0.7931169297601973\n",
      "300,50-25-10,5,45,0.9340458444663198,0.7955119035652616\n",
      "300,50-25-10,5,50,0.9312333005203206,0.7917337308231076\n",
      "300,50-25-10,5,55,0.9344677260582197,0.7976305874064361\n",
      "300,50-25-10,5,60,0.9367177612150189,0.7980752751026342\n",
      "300,50-25-10,5,65,0.9322176909014204,0.7917008731385637\n",
      "300,50-25-10,5,70,0.9354521164393194,0.7960238850706118\n",
      "300,50-25-10,5,75,0.9341864716636198,0.7935892082162243\n",
      "300,50-25-10,5,80,0.9355927436366194,0.801713902092824\n",
      "300,50-25-10,5,85,0.9362958796231191,0.7963732743176308\n",
      "300,50-25-10,5,90,0.9369990156096188,0.8030854577969659\n",
      "300,50-25-10,5,95,0.9346083532555196,0.7975910852420031\n",
      "300,50-25-10,5,100,0.9346083532555196,0.8017479242182008\n",
      "300,50-25-10,5,105,0.9339052172690199,0.7950005220306796\n",
      "300,50-25-10,6,20,0.9357333708339193,0.7947542015437886\n",
      "300,50-25-10,6,25,0.9282801293770215,0.7944920611421268\n",
      "300,50-25-10,6,30,0.929967655744621,0.7945318494454608\n",
      "300,50-25-10,6,35,0.93334270847982,0.7806658203913949\n",
      "300,50-25-10,6,40,0.9351708620447194,0.7924175716975288\n",
      "300,50-25-10,6,45,0.9348896076501195,0.7873964444102679\n",
      "300,50-25-10,6,50,0.93334270847982,0.7965530114369367\n",
      "300,50-25-10,6,55,0.9285613837716215,0.7836695506902333\n",
      "300,50-25-10,6,60,0.9351708620447194,0.7854031386874927\n",
      "300,50-25-10,6,65,0.9347489804528196,0.7898699393945182\n",
      "300,50-25-10,6,70,0.9329208268879201,0.7841422528271108\n",
      "300,50-25-10,6,75,0.9347489804528196,0.7866421372135174\n",
      "300,50-25-10,6,80,0.9305301645338209,0.7701405770075104\n",
      "300,50-25-10,6,85,0.9324989452960203,0.780301269217028\n",
      "300,50-25-10,6,90,0.9313739277176206,0.7732473503471518\n",
      "300,50-25-10,6,95,0.9308114189284208,0.7777311983799496\n",
      "300,50-25-10,6,100,0.9308114189284208,0.7824795836671612\n",
      "300,50-25-10,6,105,0.9326395724933202,0.7885434349186512\n",
      "300,50-25-10,7,20,0.929967655744621,0.7807041399349246\n",
      "300,50-25-10,7,25,0.9315145549149205,0.7806641536550671\n",
      "300,50-25-10,7,30,0.9315145549149205,0.7796994924122321\n",
      "300,50-25-10,7,35,0.9350302348474195,0.7897152926481287\n",
      "300,50-25-10,7,40,0.9306707917311208,0.7770547611692721\n",
      "300,50-25-10,7,45,0.9343270988609197,0.7810548063935498\n",
      "300,50-25-10,7,50,0.9281395021797215,0.7807251065501323\n",
      "300,50-25-10,7,55,0.9315145549149205,0.7818127060229944\n",
      "300,50-25-10,7,60,0.9319364365068205,0.7792507340932598\n",
      "300,50-25-10,7,65,0.9341864716636198,0.7779355996491444\n",
      "300,50-25-10,7,70,0.9260300942202222,0.7728404115407684\n",
      "300,50-25-10,7,75,0.9295457741527211,0.7721642603613068\n",
      "300,50-25-10,7,80,0.9244831950499226,0.7671133165296733\n",
      "300,50-25-10,7,85,0.9312333005203206,0.7781773144269749\n",
      "300,50-25-10,7,90,0.9296864013500211,0.7771372989724851\n",
      "300,50-25-10,7,95,0.9272957389959218,0.7704440515539993\n",
      "300,50-25-10,7,100,0.923358177471523,0.7720855421198488\n",
      "300,50-25-10,7,105,0.9270144846013219,0.7720974537495072\n",
      "300,50-25-10,8,20,0.9254675854310224,0.7626265271841318\n",
      "300,50-25-10,8,25,0.9288426381662214,0.7940966419504197\n",
      "300,50-25-10,8,30,0.926873857404022,0.7774727797017814\n",
      "300,50-25-10,8,35,0.9271551117986219,0.7854508309217367\n",
      "300,50-25-10,8,40,0.9316551821122205,0.7987407011631503\n",
      "300,50-25-10,8,45,0.930248910139221,0.7849775811047759\n",
      "300,50-25-10,8,50,0.923217550274223,0.7827333967451621\n",
      "300,50-25-10,8,55,0.926451975812122,0.7875362566218271\n",
      "300,50-25-10,8,60,0.9306707917311208,0.7905469164505085\n",
      "300,50-25-10,8,65,0.9237800590634229,0.7716626006505626\n",
      "300,50-25-10,8,70,0.9194206159471242,0.7725305143648824\n",
      "300,50-25-10,8,75,0.9270144846013219,0.783949930794087\n",
      "300,50-25-10,8,80,0.9272957389959218,0.7802770693993367\n",
      "300,50-25-10,8,85,0.9291238925608213,0.7807283292505193\n",
      "300,50-25-10,8,90,0.926592603009422,0.7790419522004615\n",
      "300,50-25-10,8,95,0.9249050766418225,0.772167486548429\n",
      "300,50-25-10,8,100,0.9218112783012234,0.7807984023659006\n",
      "300,50-25-10,8,105,0.9272957389959218,0.7817466744431761\n",
      "300,50-25-10,9,20,0.9244831950499226,0.7670993062748996\n",
      "300,50-25-10,9,25,0.9281395021797215,0.7879685735506999\n",
      "300,50-25-10,9,30,0.9270144846013219,0.7879644457800343\n",
      "300,50-25-10,9,35,0.9271551117986219,0.7718690751189655\n",
      "300,50-25-10,9,40,0.9256082126283223,0.763373393334895\n",
      "300,50-25-10,9,45,0.9277176205878217,0.7756850746892675\n",
      "300,50-25-10,9,50,0.9251863310364224,0.7774398100278012\n",
      "300,50-25-10,9,55,0.9277176205878217,0.7827048110851519\n",
      "300,50-25-10,9,60,0.9242019406553227,0.7780183325874365\n",
      "300,50-25-10,9,65,0.9256082126283223,0.7868375771707564\n",
      "300,50-25-10,9,70,0.923217550274223,0.7788244030134694\n",
      "300,50-25-10,9,75,0.9240613134580228,0.7777625990505923\n",
      "300,50-25-10,9,80,0.9250457038391224,0.7784884576881074\n",
      "300,50-25-10,9,85,0.9254675854310224,0.7675057758935381\n",
      "300,50-25-10,9,90,0.9225144142877233,0.7742263775214902\n",
      "300,50-25-10,9,95,0.9244831950499226,0.7777045229565208\n",
      "300,50-25-10,9,100,0.9215300239066235,0.7743763037877175\n",
      "300,50-25-10,9,105,0.9206862607228238,0.7740442593848971\n",
      "300,50-50,3,20,0.9424834763043173,0.8404294943258154\n",
      "300,50-50,3,25,0.9429053578962171,0.845063512913036\n",
      "300,50-50,3,30,0.9400928139502179,0.8252577417729131\n",
      "300,50-50,3,35,0.9414990859232175,0.8289337449740879\n",
      "300,50-50,3,40,0.9412178315286176,0.8227300510155162\n",
      "300,50-50,3,45,0.9434678666854169,0.8333924791720416\n",
      "300,50-50,3,50,0.9407959499367178,0.8305706132399905\n",
      "300,50-50,3,55,0.9420615947124173,0.8294270036574033\n",
      "300,50-50,3,60,0.9392490507664182,0.822830318123831\n",
      "300,50-50,3,65,0.9386865419772183,0.8184115520225044\n",
      "300,50-50,3,70,0.9396709323583181,0.8159231242509729\n",
      "300,50-50,3,75,0.9412178315286176,0.8220709277304676\n",
      "300,50-50,3,80,0.9377021515961187,0.8107712585837586\n",
      "300,50-50,3,85,0.9364365068204191,0.8065129016620572\n",
      "300,50-50,3,90,0.9386865419772183,0.8224254236485886\n",
      "300,50-50,3,95,0.9385459147799184,0.8192833906798452\n",
      "300,50-50,3,100,0.9251863310364224,0.79785322664011\n",
      "300,50-50,3,105,0.9364365068204191,0.8137147405944392\n",
      "300,50-50,4,20,0.9340458444663198,0.8155090447095691\n",
      "300,50-50,4,25,0.9378427787934186,0.8035797603339118\n",
      "300,50-50,4,30,0.9327801996906202,0.8042722330673874\n",
      "300,50-50,4,35,0.9324989452960203,0.8102059264935372\n",
      "300,50-50,4,40,0.9381240331880185,0.8166451866528656\n",
      "300,50-50,4,45,0.9405146955421179,0.8292953846875512\n",
      "300,50-50,4,50,0.9320770637041204,0.811457558102013\n",
      "300,50-50,4,55,0.9384052875826184,0.8135553586522649\n",
      "300,50-50,4,60,0.9362958796231191,0.8078775868705913\n",
      "300,50-50,4,65,0.9372802700042188,0.8139513693724232\n",
      "300,50-50,4,70,0.9346083532555196,0.8073631463916326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300,50-50,4,75,0.9354521164393194,0.8047224045606232\n",
      "300,50-50,4,80,0.9343270988609197,0.8050451860889529\n",
      "300,50-50,4,85,0.9369990156096188,0.8131476875733016\n",
      "300,50-50,4,90,0.9341864716636198,0.8025661847463202\n",
      "300,50-50,4,95,0.9375615243988187,0.811202549638737\n",
      "300,50-50,4,100,0.93320208128252,0.795679092534772\n",
      "300,50-50,4,105,0.9319364365068205,0.7977017240375953\n",
      "300,50-50,5,20,0.9362958796231191,0.8162295774735976\n",
      "300,50-50,5,25,0.9377021515961187,0.8184530825142601\n",
      "300,50-50,5,30,0.9309520461257207,0.7911123692691007\n",
      "300,50-50,5,35,0.9324989452960203,0.8054822323078286\n",
      "300,50-50,5,40,0.9340458444663198,0.8050841316037703\n",
      "300,50-50,5,45,0.9353114892420195,0.8056714194680724\n",
      "300,50-50,5,50,0.9315145549149205,0.7931461767856135\n",
      "300,50-50,5,55,0.9344677260582197,0.8037208692606991\n",
      "300,50-50,5,60,0.929967655744621,0.798629383987341\n",
      "300,50-50,5,65,0.9313739277176206,0.7929176749141074\n",
      "300,50-50,5,70,0.9329208268879201,0.7957777868787107\n",
      "300,50-50,5,75,0.9341864716636198,0.7965461401155322\n",
      "300,50-50,5,80,0.9275769933905217,0.793782789442576\n",
      "300,50-50,5,85,0.9327801996906202,0.7957315458059274\n",
      "300,50-50,5,90,0.93334270847982,0.7923627611959528\n",
      "300,50-50,5,95,0.9324989452960203,0.7989187628873515\n",
      "300,50-50,5,100,0.9327801996906202,0.796307852026095\n",
      "300,50-50,5,105,0.9322176909014204,0.7948738775897531\n",
      "300,50-50,6,20,0.9272957389959218,0.7873996181277709\n",
      "300,50-50,6,25,0.926451975812122,0.7901273362807707\n",
      "300,50-50,6,30,0.9295457741527211,0.7963110432149293\n",
      "300,50-50,6,35,0.9319364365068205,0.7967896633074063\n",
      "300,50-50,6,40,0.9312333005203206,0.7919306068106446\n",
      "300,50-50,6,45,0.9334833356771199,0.8038571096859871\n",
      "300,50-50,6,50,0.9305301645338209,0.7939306061646544\n",
      "300,50-50,6,55,0.9350302348474195,0.8022965479610219\n",
      "300,50-50,6,60,0.9295457741527211,0.7935800604229608\n",
      "300,50-50,6,65,0.9306707917311208,0.7928332820335143\n",
      "300,50-50,6,70,0.9317958093095204,0.7937508345222932\n",
      "300,50-50,6,75,0.9315145549149205,0.7975100889263764\n",
      "300,50-50,6,80,0.9309520461257207,0.7921140219885497\n",
      "300,50-50,6,85,0.9334833356771199,0.8020931176105522\n",
      "300,50-50,6,90,0.9309520461257207,0.7950726329370132\n",
      "300,50-50,6,95,0.9295457741527211,0.7936547614482229\n",
      "300,50-50,6,100,0.9287020109689214,0.7922705774585538\n",
      "300,50-50,6,105,0.929967655744621,0.7944525994201529\n",
      "300,50-50,7,20,0.9312333005203206,0.7960919745688826\n",
      "300,50-50,7,25,0.9323583180987203,0.7895458738678581\n",
      "300,50-50,7,30,0.9306707917311208,0.7926292282962969\n",
      "300,50-50,7,35,0.9317958093095204,0.7969541265642263\n",
      "300,50-50,7,40,0.9271551117986219,0.7980490779339835\n",
      "300,50-50,7,45,0.9267332302067219,0.7924073009707028\n",
      "300,50-50,7,50,0.929967655744621,0.7906796517994819\n",
      "300,50-50,7,55,0.9310926733230207,0.7850433537595753\n",
      "300,50-50,7,60,0.9323583180987203,0.799967478036906\n",
      "300,50-50,7,65,0.9340458444663198,0.8044412365108496\n",
      "300,50-50,7,70,0.9329208268879201,0.8026314127043971\n",
      "300,50-50,7,75,0.9339052172690199,0.8071745652562407\n",
      "300,50-50,7,80,0.9344677260582197,0.8019246011645499\n",
      "300,50-50,7,85,0.9354521164393194,0.8019641253742509\n",
      "300,50-50,7,90,0.9337645900717199,0.8063752150192153\n",
      "300,50-50,7,95,0.9250457038391224,0.796776925451771\n",
      "300,50-50,7,100,0.9291238925608213,0.7959434935519673\n",
      "300,50-50,7,105,0.9295457741527211,0.8007554680147301\n",
      "300,50-50,8,20,0.9312333005203206,0.7917816133958452\n",
      "300,50-50,8,25,0.929827028547321,0.7886335633118898\n",
      "300,50-50,8,30,0.9279988749824216,0.7852476659477535\n",
      "300,50-50,8,35,0.9308114189284208,0.7863142355170822\n",
      "300,50-50,8,40,0.9296864013500211,0.7956468619256031\n",
      "300,50-50,8,45,0.9291238925608213,0.7920920457651341\n",
      "300,50-50,8,50,0.9275769933905217,0.7862901260269037\n",
      "300,50-50,8,55,0.9263113486148221,0.7863456007248257\n",
      "300,50-50,8,60,0.9288426381662214,0.8023885685529671\n",
      "300,50-50,8,65,0.93362396287442,0.798621966569056\n",
      "300,50-50,8,70,0.9329208268879201,0.7997733718450002\n",
      "300,50-50,8,75,0.9284207565743214,0.8032173353667229\n",
      "300,50-50,8,80,0.9303895373365209,0.794215678934869\n",
      "300,50-50,8,85,0.9322176909014204,0.8003951444491123\n",
      "300,50-50,8,90,0.9292645197581212,0.788437900838003\n",
      "300,50-50,8,95,0.9310926733230207,0.7922789816863779\n",
      "300,50-50,8,100,0.9313739277176206,0.7906798492345914\n",
      "300,50-50,8,105,0.9320770637041204,0.7978610383128094\n",
      "300,50-50,9,20,0.9291238925608213,0.7901073524441578\n",
      "300,50-50,9,25,0.9267332302067219,0.7918645983972635\n",
      "300,50-50,9,30,0.9249050766418225,0.799009079117134\n",
      "300,50-50,9,35,0.9316551821122205,0.7999977995602506\n",
      "300,50-50,9,40,0.9278582477851216,0.7908210638547137\n",
      "300,50-50,9,45,0.9306707917311208,0.7920031650841245\n",
      "300,50-50,9,50,0.9303895373365209,0.7906074881962178\n",
      "300,50-50,9,55,0.9326395724933202,0.795045892231521\n",
      "300,50-50,9,60,0.9285613837716215,0.7955982353235358\n",
      "300,50-50,9,65,0.9313739277176206,0.792421794629623\n",
      "300,50-50,9,70,0.930248910139221,0.7856064936557131\n",
      "300,50-50,9,75,0.9320770637041204,0.7928923862925727\n",
      "300,50-50,9,80,0.9320770637041204,0.7925677818155842\n",
      "300,50-50,9,85,0.9320770637041204,0.7954935536369835\n",
      "300,50-50,9,90,0.929827028547321,0.7970565002344161\n",
      "300,50-50,9,95,0.9291238925608213,0.7974081631532114\n",
      "300,50-50,9,100,0.929827028547321,0.7998731181553147\n",
      "300,50-50,9,105,0.929827028547321,0.8024663829950206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shark\\Anaconda3\\lib\\site-packages\\sklearn\\metrics\\classification.py:1437: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no predicted samples.\n",
      "  'precision', 'predicted', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300,16-8,3,20,0.9251863310364224,0.5542576356042573\n",
      "300,16-8,3,25,0.9220925326958234,0.5426761099186006\n",
      "300,16-8,3,30,0.9227956686823232,0.5464178764593538\n",
      "300,16-8,3,35,0.9393896779637182,0.8307557234909572\n",
      "300,16-8,3,40,0.9413584587259176,0.8352276179449408\n",
      "300,16-8,3,45,0.9405146955421179,0.8328662703088243\n",
      "300,16-8,3,50,0.9417803403178174,0.8385053504562205\n",
      "300,16-8,3,55,0.9416397131205175,0.8402948420788362\n",
      "300,16-8,3,60,0.943186612290817,0.8391352157590051\n",
      "300,16-8,3,65,0.9414990859232175,0.8309884320170409\n",
      "300,16-8,3,70,0.9417803403178174,0.8343953778177884\n",
      "300,16-8,3,75,0.9430459850935171,0.8412829753991434\n",
      "300,16-8,3,80,0.9414990859232175,0.8370330420312354\n",
      "300,16-8,3,85,0.9413584587259176,0.8341637503682963\n",
      "300,16-8,3,90,0.9320770637041204,0.8263356572297152\n",
      "300,16-8,3,95,0.9377021515961187,0.813600839723466\n",
      "300,16-8,3,100,0.9386865419772183,0.8193438940870573\n",
      "300,16-8,3,105,0.939952186752918,0.8285464864715909\n",
      "300,16-8,4,20,0.9369990156096188,0.8202360125455218\n",
      "300,16-8,4,25,0.9388271691745184,0.8250283677730782\n",
      "300,16-8,4,30,0.9379834059907186,0.8190652939169736\n",
      "300,16-8,4,35,0.9393896779637182,0.8198933460518013\n",
      "300,16-8,4,40,0.9372802700042188,0.812988108446065\n",
      "300,16-8,4,45,0.9357333708339193,0.8149868870034368\n",
      "300,16-8,4,50,0.9381240331880185,0.816257550820378\n",
      "300,16-8,4,55,0.9364365068204191,0.8170600252756852\n",
      "300,16-8,4,60,0.9367177612150189,0.8221504025369765\n",
      "300,16-8,4,65,0.9367177612150189,0.8264257109516778\n",
      "300,16-8,4,70,0.9374208972015188,0.822008907487846\n",
      "300,16-8,4,75,0.9362958796231191,0.8135380064426835\n",
      "300,16-8,4,80,0.93320208128252,0.8249493971241938\n",
      "300,16-8,4,85,0.9377021515961187,0.823541646913668\n",
      "300,16-8,4,90,0.9357333708339193,0.8124148158471939\n",
      "300,16-8,4,95,0.9361552524258192,0.8117175724285887\n",
      "300,16-8,4,100,0.9374208972015188,0.8138716809279826\n",
      "300,16-8,4,105,0.9371396428069189,0.8132369313022217\n",
      "300,16-8,5,20,0.9369990156096188,0.809864649626676\n",
      "300,16-8,5,25,0.9350302348474195,0.8056251131915347\n",
      "300,16-8,5,30,0.9346083532555196,0.807430654732339\n",
      "300,16-8,5,35,0.9341864716636198,0.8098673708538313\n",
      "300,16-8,5,40,0.9348896076501195,0.8080445653489811\n",
      "300,16-8,5,45,0.9372802700042188,0.8144935886761134\n",
      "300,16-8,5,50,0.9329208268879201,0.8066818520267725\n",
      "300,16-8,5,55,0.9351708620447194,0.8027758495289415\n",
      "300,16-8,5,60,0.93362396287442,0.8010115686380604\n",
      "300,16-8,5,65,0.9357333708339193,0.8114248074181366\n",
      "300,16-8,5,70,0.9351708620447194,0.8110093092487208\n",
      "300,16-8,5,75,0.9361552524258192,0.8136053777303118\n",
      "300,16-8,5,80,0.9353114892420195,0.8101674533744591\n",
      "300,16-8,5,85,0.9362958796231191,0.8096510030243756\n",
      "300,16-8,5,90,0.9362958796231191,0.8120635005676201\n",
      "300,16-8,5,95,0.9354521164393194,0.8099859252571638\n",
      "300,16-8,5,100,0.9351708620447194,0.8104885709325048\n",
      "300,16-8,5,105,0.93334270847982,0.8073675877378568\n",
      "300,16-8,6,20,0.9374208972015188,0.8214823446709776\n",
      "300,16-8,6,25,0.9347489804528196,0.8116735803627152\n",
      "300,16-8,6,30,0.9329208268879201,0.7998709697178881\n",
      "300,16-8,6,35,0.9324989452960203,0.8042130371651015\n",
      "300,16-8,6,40,0.9334833356771199,0.8008132871876009\n",
      "300,16-8,6,45,0.9323583180987203,0.7900476537990828\n",
      "300,16-8,6,50,0.9319364365068205,0.7925507272024884\n",
      "300,16-8,6,55,0.93320208128252,0.8025117995181335\n",
      "300,16-8,6,60,0.9324989452960203,0.7983987097951349\n",
      "300,16-8,6,65,0.9337645900717199,0.8035129615970361\n",
      "300,16-8,6,70,0.9340458444663198,0.8020368942717019\n",
      "300,16-8,6,75,0.9309520461257207,0.7953843150786453\n",
      "300,16-8,6,80,0.9324989452960203,0.7984974696477392\n",
      "300,16-8,6,85,0.9344677260582197,0.8061357575156439\n",
      "300,16-8,6,90,0.9341864716636198,0.8055259104262652\n",
      "300,16-8,6,95,0.9316551821122205,0.7976626088399068\n",
      "300,16-8,6,100,0.9309520461257207,0.7909733869902075\n",
      "300,16-8,6,105,0.9316551821122205,0.7968683128416854\n",
      "300,16-8,7,20,0.9312333005203206,0.7946594517137685\n",
      "300,16-8,7,25,0.929827028547321,0.786583279522473\n",
      "300,16-8,7,30,0.9310926733230207,0.7927095073108262\n",
      "300,16-8,7,35,0.9319364365068205,0.7919400494791948\n",
      "300,16-8,7,40,0.9306707917311208,0.7870902795450337\n",
      "300,16-8,7,45,0.9294051469554212,0.7812138261399846\n",
      "300,16-8,7,50,0.9303895373365209,0.7853598320045027\n",
      "300,16-8,7,55,0.9301082829419209,0.7892699380036726\n",
      "300,16-8,7,60,0.9308114189284208,0.7943682093911089\n",
      "300,16-8,7,65,0.9292645197581212,0.7887755406968383\n",
      "300,16-8,7,70,0.9316551821122205,0.7966100358182203\n",
      "300,16-8,7,75,0.9287020109689214,0.7879459059375068\n",
      "300,16-8,7,80,0.9289832653635213,0.7839558412605232\n",
      "300,16-8,7,85,0.9242019406553227,0.7881072092229289\n",
      "300,16-8,7,90,0.9306707917311208,0.7943735482449069\n",
      "300,16-8,7,95,0.9306707917311208,0.7947155687004089\n",
      "300,16-8,7,100,0.9303895373365209,0.7921578192494737\n",
      "300,16-8,7,105,0.9303895373365209,0.7924434792964773\n",
      "300,16-8,8,20,0.9317958093095204,0.7947268746184794\n",
      "300,16-8,8,25,0.9289832653635213,0.7896590328543907\n",
      "300,16-8,8,30,0.9281395021797215,0.786190004246461\n",
      "300,16-8,8,35,0.9295457741527211,0.7932050127534875\n",
      "300,16-8,8,40,0.929967655744621,0.7915751595353862\n",
      "300,16-8,8,45,0.9289832653635213,0.7831358659129327\n",
      "300,16-8,8,50,0.9289832653635213,0.7926339163104129\n",
      "300,16-8,8,55,0.9312333005203206,0.7931812344586396\n",
      "300,16-8,8,60,0.9306707917311208,0.7943414669943293\n",
      "300,16-8,8,65,0.9308114189284208,0.7989724089417373\n",
      "300,16-8,8,70,0.9281395021797215,0.7841196515739391\n",
      "300,16-8,8,75,0.9292645197581212,0.787667176761644\n",
      "300,16-8,8,80,0.9287020109689214,0.7919798329482743\n",
      "300,16-8,8,85,0.9294051469554212,0.7918640060532166\n",
      "300,16-8,8,90,0.9289832653635213,0.7913339240778613\n",
      "300,16-8,8,95,0.9294051469554212,0.7945210010682487\n",
      "300,16-8,8,100,0.923498804668823,0.7914158151983764\n",
      "300,16-8,8,105,0.9295457741527211,0.7850761452196737\n",
      "300,16-8,9,20,0.9294051469554212,0.7958719799629357\n",
      "300,16-8,9,25,0.9279988749824216,0.7805960903843611\n",
      "300,16-8,9,30,0.9215300239066235,0.7800190733853709\n",
      "300,16-8,9,35,0.9279988749824216,0.782847290848685\n",
      "300,16-8,9,40,0.9277176205878217,0.7877554224513669\n",
      "300,16-8,9,45,0.9281395021797215,0.7898116691071179\n",
      "300,16-8,9,50,0.9243425678526227,0.7670815251550841\n",
      "300,16-8,9,55,0.923639431866123,0.7515665913974677\n",
      "300,16-8,9,60,0.9279988749824216,0.7931802606507702\n",
      "300,16-8,9,65,0.926451975812122,0.7867108010089753\n",
      "300,16-8,9,70,0.9279988749824216,0.7912414553880097\n",
      "300,16-8,9,75,0.9271551117986219,0.7896293741648058\n",
      "300,16-8,9,80,0.929827028547321,0.7956825326354351\n",
      "300,16-8,9,85,0.9278582477851216,0.7898601820301646\n",
      "300,16-8,9,90,0.9287020109689214,0.793398674285623\n",
      "300,16-8,9,95,0.926451975812122,0.7875968251029536\n",
      "300,16-8,9,100,0.9275769933905217,0.7884411418451639\n",
      "300,16-8,9,105,0.9282801293770215,0.7941009883195633\n",
      "300,32-16-8,3,20,0.9386865419772183,0.8220685867584434\n",
      "300,32-16-8,3,25,0.9419209675151174,0.8372574532352247\n",
      "300,32-16-8,3,30,0.9420615947124173,0.8357791535903938\n",
      "300,32-16-8,3,35,0.9412178315286176,0.8387748755123514\n",
      "300,32-16-8,3,40,0.9367177612150189,0.8334957285112871\n",
      "300,32-16-8,3,45,0.9429053578962171,0.8339537928714337\n",
      "300,32-16-8,3,50,0.9423428491070173,0.8332688336662463\n",
      "300,32-16-8,3,55,0.9416397131205175,0.8344996608801295\n",
      "300,32-16-8,3,60,0.9430459850935171,0.8385644117881959\n",
      "300,32-16-8,3,65,0.9357333708339193,0.8327912108694985\n",
      "300,32-16-8,3,70,0.9378427787934186,0.8284753288732043\n",
      "300,32-16-8,3,75,0.9389677963718183,0.8269618040683232\n",
      "300,32-16-8,3,80,0.9416397131205175,0.8314575437440225\n",
      "300,32-16-8,3,85,0.93334270847982,0.8189341156344486\n",
      "300,32-16-8,3,90,0.943327239488117,0.8379032286474907\n",
      "300,32-16-8,3,95,0.9410772043313177,0.834444243505207\n",
      "300,32-16-8,3,100,0.9400928139502179,0.8287065426279802\n",
      "300,32-16-8,3,105,0.9400928139502179,0.8297573434938128\n",
      "300,32-16-8,4,20,0.9409365771340177,0.8326518003632065\n",
      "300,32-16-8,4,25,0.9372802700042188,0.8184354093443247\n",
      "300,32-16-8,4,30,0.9348896076501195,0.8166363058247667\n",
      "300,32-16-8,4,35,0.9378427787934186,0.8191909423196506\n",
      "300,32-16-8,4,40,0.9391084235691183,0.8169350014076594\n",
      "300,32-16-8,4,45,0.9400928139502179,0.8228910702666484\n",
      "300,32-16-8,4,50,0.9310926733230207,0.8111150736766932\n",
      "300,32-16-8,4,55,0.9355927436366194,0.8099206405904192\n",
      "300,32-16-8,4,60,0.9354521164393194,0.8029716882431405\n",
      "300,32-16-8,4,65,0.9358739980312193,0.8030641680745688\n",
      "300,32-16-8,4,70,0.9369990156096188,0.8082746317055616\n",
      "300,32-16-8,4,75,0.9361552524258192,0.8107058827725089\n",
      "300,32-16-8,4,80,0.9358739980312193,0.8021504726162766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300,32-16-8,4,85,0.9320770637041204,0.8026525487147845\n",
      "300,32-16-8,4,90,0.9369990156096188,0.8117678616252145\n",
      "300,32-16-8,4,95,0.9368583884123189,0.8073843555305706\n",
      "300,32-16-8,4,100,0.9291238925608213,0.8003357558229447\n",
      "300,32-16-8,4,105,0.9329208268879201,0.7984081284098163\n",
      "300,32-16-8,5,20,0.9346083532555196,0.8040069810825794\n",
      "300,32-16-8,5,25,0.9357333708339193,0.7975497060896092\n",
      "300,32-16-8,5,30,0.9327801996906202,0.7895910552810962\n",
      "300,32-16-8,5,35,0.9323583180987203,0.7884578682994148\n",
      "300,32-16-8,5,40,0.9301082829419209,0.7893008068920514\n",
      "300,32-16-8,5,45,0.9306707917311208,0.7874243672606082\n",
      "300,32-16-8,5,50,0.9270144846013219,0.7921533694512419\n",
      "300,32-16-8,5,55,0.9296864013500211,0.7888746129442504\n",
      "300,32-16-8,5,60,0.9263113486148221,0.7866540995136271\n",
      "300,32-16-8,5,65,0.9301082829419209,0.7924419148175644\n",
      "300,32-16-8,5,70,0.9327801996906202,0.7934059982230378\n",
      "300,32-16-8,5,75,0.9285613837716215,0.7833380018533392\n",
      "300,32-16-8,5,80,0.9309520461257207,0.7935916830514316\n",
      "300,32-16-8,5,85,0.9308114189284208,0.7923409413066387\n",
      "300,32-16-8,5,90,0.9274363661932218,0.7820384028610378\n",
      "300,32-16-8,5,95,0.9256082126283223,0.7918545158544456\n",
      "300,32-16-8,5,100,0.9278582477851216,0.7844115316765419\n",
      "300,32-16-8,5,105,0.9296864013500211,0.7855228225179802\n",
      "300,32-16-8,6,20,0.9291238925608213,0.7835836197726979\n",
      "300,32-16-8,6,25,0.9317958093095204,0.7861192115900005\n",
      "300,32-16-8,6,30,0.9301082829419209,0.7745112683725228\n",
      "300,32-16-8,6,35,0.929967655744621,0.7774044735263604\n",
      "300,32-16-8,6,40,0.9229362958796231,0.7713842846620468\n",
      "300,32-16-8,6,45,0.9243425678526227,0.7823034459595474\n",
      "300,32-16-8,6,50,0.9274363661932218,0.7813485076126822\n",
      "300,32-16-8,6,55,0.9270144846013219,0.7869926525657417\n",
      "300,32-16-8,6,60,0.9243425678526227,0.7878958858567341\n",
      "300,32-16-8,6,65,0.9275769933905217,0.7844672548289554\n",
      "300,32-16-8,6,70,0.926873857404022,0.7802206929856332\n",
      "300,32-16-8,6,75,0.9282801293770215,0.7868336066398189\n",
      "300,32-16-8,6,80,0.9263113486148221,0.7882076903770333\n",
      "300,32-16-8,6,85,0.9272957389959218,0.782058184346028\n",
      "300,32-16-8,6,90,0.9263113486148221,0.7750370866682839\n",
      "300,32-16-8,6,95,0.9257488398256223,0.7730800976306041\n",
      "300,32-16-8,6,100,0.9254675854310224,0.7801079325254445\n",
      "300,32-16-8,6,105,0.929967655744621,0.7766960743099386\n",
      "300,32-16-8,7,20,0.9272957389959218,0.7755244489849827\n",
      "300,32-16-8,7,25,0.9263113486148221,0.7745750549270047\n",
      "300,32-16-8,7,30,0.9277176205878217,0.7694023442388049\n",
      "300,32-16-8,7,35,0.9237800590634229,0.7760468585080947\n",
      "300,32-16-8,7,40,0.9188581071579244,0.7213406973054135\n",
      "300,32-16-8,7,45,0.9279988749824216,0.7744046182034863\n",
      "300,32-16-8,7,50,0.9260300942202222,0.7724219308527035\n",
      "300,32-16-8,7,55,0.9256082126283223,0.7772851570690742\n",
      "300,32-16-8,7,60,0.9250457038391224,0.7734865096507262\n",
      "300,32-16-8,7,65,0.9230769230769231,0.770420872206287\n",
      "300,32-16-8,7,70,0.9249050766418225,0.7771741376768473\n",
      "300,32-16-8,7,75,0.9260300942202222,0.7753885777985884\n",
      "300,32-16-8,7,80,0.9257488398256223,0.7740435647360752\n",
      "300,32-16-8,7,85,0.9205456335255239,0.7620467130993028\n",
      "300,32-16-8,7,90,0.9208268879201238,0.7709068118196317\n",
      "300,32-16-8,7,95,0.9261707214175221,0.7793342091332992\n",
      "300,32-16-8,7,100,0.926592603009422,0.7733176171215108\n",
      "300,32-16-8,7,105,0.9261707214175221,0.7786983554134735\n",
      "300,32-16-8,8,20,0.920264379130924,0.7666967290535469\n",
      "300,32-16-8,8,25,0.9289832653635213,0.777479627721215\n",
      "300,32-16-8,8,30,0.9282801293770215,0.778026066894102\n",
      "300,32-16-8,8,35,0.926592603009422,0.7749736307409011\n",
      "300,32-16-8,8,40,0.9175924623822247,0.7683401901155712\n",
      "300,32-16-8,8,45,0.9184362255660244,0.7363428808221008\n",
      "300,32-16-8,8,50,0.9218112783012234,0.7280905672889432\n",
      "300,32-16-8,8,55,0.9287020109689214,0.7740444201443194\n",
      "300,32-16-8,8,60,0.9242019406553227,0.7667723344450986\n",
      "300,32-16-8,8,65,0.9263113486148221,0.7745666403149242\n",
      "300,32-16-8,8,70,0.923498804668823,0.7812393906843296\n",
      "300,32-16-8,8,75,0.9253269582337224,0.7750589843119737\n",
      "300,32-16-8,8,80,0.9251863310364224,0.7657547198106928\n",
      "300,32-16-8,8,85,0.9263113486148221,0.7774385704114649\n",
      "300,32-16-8,8,90,0.9195612431444241,0.7707940118884086\n",
      "300,32-16-8,8,95,0.9213893967093236,0.77376427980589\n",
      "300,32-16-8,8,100,0.926592603009422,0.7748607280532177\n",
      "300,32-16-8,8,105,0.9257488398256223,0.7768160654171017\n",
      "300,32-16-8,9,20,0.9284207565743214,0.781003366830089\n",
      "300,32-16-8,9,25,0.920123751933624,0.7754231729911552\n",
      "300,32-16-8,9,30,0.9253269582337224,0.7750128309735782\n",
      "300,32-16-8,9,35,0.926873857404022,0.7734302114532187\n",
      "300,32-16-8,9,40,0.9275769933905217,0.7747311060240437\n",
      "300,32-16-8,9,45,0.9282801293770215,0.7740680972894601\n",
      "300,32-16-8,9,50,0.920264379130924,0.7685030634182644\n",
      "300,32-16-8,9,55,0.9275769933905217,0.7765647459746828\n",
      "300,32-16-8,9,60,0.9288426381662214,0.7805708764345058\n",
      "300,32-16-8,9,65,0.9274363661932218,0.7761345907241206\n",
      "300,32-16-8,9,70,0.9239206862607229,0.7714556532988683\n",
      "300,32-16-8,9,75,0.9285613837716215,0.7760123232141988\n",
      "300,32-16-8,9,80,0.9270144846013219,0.7737270615757602\n",
      "300,32-16-8,9,85,0.9271551117986219,0.7755798203301302\n",
      "300,32-16-8,9,90,0.9289832653635213,0.7833250200943408\n",
      "300,32-16-8,9,95,0.9219519054985235,0.7806563377136767\n",
      "300,32-16-8,9,100,0.9294051469554212,0.7884019001946035\n",
      "300,32-16-8,9,105,0.9271551117986219,0.7764585824563771\n",
      "300,8-8-8,3,20,0.9230769230769231,0.5328054758038652\n",
      "300,8-8-8,3,25,0.9361552524258192,0.8067864145892893\n",
      "300,8-8-8,3,30,0.9386865419772183,0.8374798827488669\n",
      "300,8-8-8,3,35,0.9391084235691183,0.8360436712871934\n",
      "300,8-8-8,3,40,0.9405146955421179,0.8420261411155074\n",
      "300,8-8-8,3,45,0.9378427787934186,0.8419869151769775\n",
      "300,8-8-8,3,50,0.9396709323583181,0.837319557811475\n",
      "300,8-8-8,3,55,0.940233441147518,0.8384147168012331\n",
      "300,8-8-8,3,60,0.9362958796231191,0.8377186892555238\n",
      "300,8-8-8,3,65,0.9378427787934186,0.835543091071917\n",
      "300,8-8-8,3,70,0.940233441147518,0.8390466816147827\n",
      "300,8-8-8,3,75,0.9406553227394178,0.839606348422218\n",
      "300,8-8-8,3,80,0.9393896779637182,0.8323524381247576\n",
      "300,8-8-8,3,85,0.9391084235691183,0.8313920174481654\n",
      "300,8-8-8,3,90,0.9375615243988187,0.8363310612414621\n",
      "300,8-8-8,3,95,0.9412178315286176,0.8374351730649585\n",
      "300,8-8-8,3,100,0.9330614540852201,0.8267880037044989\n",
      "300,8-8-8,3,105,0.9405146955421179,0.8370385961270279\n",
      "300,8-8-8,4,20,0.9305301645338209,0.8279357394047867\n",
      "300,8-8-8,4,25,0.9400928139502179,0.8368114380937937\n",
      "300,8-8-8,4,30,0.9344677260582197,0.8311015169812618\n",
      "300,8-8-8,4,35,0.9386865419772183,0.8328989440873977\n",
      "300,8-8-8,4,40,0.9367177612150189,0.830199337643764\n",
      "300,8-8-8,4,45,0.936577134017719,0.8280939527313573\n",
      "300,8-8-8,4,50,0.9364365068204191,0.8248266297889133\n",
      "300,8-8-8,4,55,0.9275769933905217,0.8220474329152315\n",
      "300,8-8-8,4,60,0.9361552524258192,0.8237313108271831\n",
      "300,8-8-8,4,65,0.9334833356771199,0.8246536123093083\n",
      "300,8-8-8,4,70,0.9355927436366194,0.8204197292221206\n",
      "300,8-8-8,4,75,0.9358739980312193,0.8238719727860304\n",
      "300,8-8-8,4,80,0.9350302348474195,0.8212592308817145\n",
      "300,8-8-8,4,85,0.9334833356771199,0.8236514658603976\n",
      "300,8-8-8,4,90,0.9351708620447194,0.8243292995847072\n",
      "300,8-8-8,4,95,0.9351708620447194,0.8266670180767987\n",
      "300,8-8-8,4,100,0.9274363661932218,0.8191888232715141\n",
      "300,8-8-8,4,105,0.9347489804528196,0.8265884117526398\n",
      "300,8-8-8,5,20,0.930248910139221,0.8236422497761948\n",
      "300,8-8-8,5,25,0.9316551821122205,0.825693317731894\n",
      "300,8-8-8,5,30,0.9315145549149205,0.8204718282207945\n",
      "300,8-8-8,5,35,0.923217550274223,0.8132100511247415\n",
      "300,8-8-8,5,40,0.9277176205878217,0.8208462270811778\n",
      "300,8-8-8,5,45,0.9306707917311208,0.8230709085940845\n",
      "300,8-8-8,5,50,0.9317958093095204,0.8208823094459717\n",
      "300,8-8-8,5,55,0.9284207565743214,0.8168360806375996\n",
      "300,8-8-8,5,60,0.9272957389959218,0.8140583762468254\n",
      "300,8-8-8,5,65,0.926451975812122,0.8174604730873302\n",
      "300,8-8-8,5,70,0.9274363661932218,0.8141089542055725\n",
      "300,8-8-8,5,75,0.930248910139221,0.8140633355239331\n",
      "300,8-8-8,5,80,0.9263113486148221,0.8139382960296474\n",
      "300,8-8-8,5,85,0.929827028547321,0.8179421473473706\n",
      "300,8-8-8,5,90,0.9267332302067219,0.8168003851780078\n",
      "300,8-8-8,5,95,0.9260300942202222,0.8145983115353764\n",
      "300,8-8-8,5,100,0.9267332302067219,0.8161628154271368\n",
      "300,8-8-8,5,105,0.9301082829419209,0.8190878846976603\n",
      "300,8-8-8,6,20,0.9284207565743214,0.8174183564235911\n",
      "300,8-8-8,6,25,0.9242019406553227,0.8078778956549245\n",
      "300,8-8-8,6,30,0.9211081423147237,0.8089041025432374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300,8-8-8,6,35,0.9287020109689214,0.8131012022566594\n",
      "300,8-8-8,6,40,0.9230769230769231,0.810174578121464\n",
      "300,8-8-8,6,45,0.923639431866123,0.8165642223211701\n",
      "300,8-8-8,6,50,0.9275769933905217,0.8161465633975585\n",
      "300,8-8-8,6,55,0.9261707214175221,0.8162627203844556\n",
      "300,8-8-8,6,60,0.9223737870904233,0.8169973524370424\n",
      "300,8-8-8,6,65,0.9213893967093236,0.8130826738838666\n",
      "300,8-8-8,6,70,0.9256082126283223,0.8110601592869208\n",
      "300,8-8-8,6,75,0.9223737870904233,0.8112599649587647\n",
      "300,8-8-8,6,80,0.9250457038391224,0.810956155073787\n",
      "300,8-8-8,6,85,0.9247644494445225,0.8143979262437249\n",
      "300,8-8-8,6,90,0.923639431866123,0.8092520586436548\n",
      "300,8-8-8,6,95,0.9257488398256223,0.815522502351485\n",
      "300,8-8-8,6,100,0.9267332302067219,0.8099572382774305\n",
      "300,8-8-8,6,105,0.9282801293770215,0.8118207625154477\n",
      "300,8-8-8,7,20,0.9225144142877233,0.8065935030275222\n",
      "300,8-8-8,7,25,0.926592603009422,0.8153279054184962\n",
      "300,8-8-8,7,30,0.9237800590634229,0.8074392186765991\n",
      "300,8-8-8,7,35,0.9247644494445225,0.8102279425080702\n",
      "300,8-8-8,7,40,0.926451975812122,0.8149042500607679\n",
      "300,8-8-8,7,45,0.9254675854310224,0.8047260112614598\n",
      "300,8-8-8,7,50,0.9244831950499226,0.809277990543209\n",
      "300,8-8-8,7,55,0.9227956686823232,0.8048935003266214\n",
      "300,8-8-8,7,60,0.926451975812122,0.809707252255175\n",
      "300,8-8-8,7,65,0.9257488398256223,0.8097736546049418\n",
      "300,8-8-8,7,70,0.9261707214175221,0.8088530984845783\n",
      "300,8-8-8,7,75,0.9272957389959218,0.801508824450926\n",
      "300,8-8-8,7,80,0.9278582477851216,0.8111295718287316\n",
      "300,8-8-8,7,85,0.9291238925608213,0.8146619360772371\n",
      "300,8-8-8,7,90,0.9244831950499226,0.805954919828399\n",
      "300,8-8-8,7,95,0.9260300942202222,0.7932684418544621\n",
      "300,8-8-8,7,100,0.9313739277176206,0.8177142215335601\n",
      "300,8-8-8,7,105,0.9292645197581212,0.8111055571566785\n",
      "300,8-8-8,8,20,0.9284207565743214,0.8052911819233085\n",
      "300,8-8-8,8,25,0.9226550414850232,0.7989413084756439\n",
      "300,8-8-8,8,30,0.9277176205878217,0.8160989117860155\n",
      "300,8-8-8,8,35,0.9254675854310224,0.7966186093550199\n",
      "300,8-8-8,8,40,0.9279988749824216,0.8061806256010015\n",
      "300,8-8-8,8,45,0.9277176205878217,0.7957434875848332\n",
      "300,8-8-8,8,50,0.926873857404022,0.7907239832922719\n",
      "300,8-8-8,8,55,0.9251863310364224,0.7868964338140879\n",
      "300,8-8-8,8,60,0.9260300942202222,0.814063639071324\n",
      "300,8-8-8,8,65,0.926592603009422,0.7887955239190138\n",
      "300,8-8-8,8,70,0.9263113486148221,0.7996741095232819\n",
      "300,8-8-8,8,75,0.9278582477851216,0.7987160877614125\n",
      "300,8-8-8,8,80,0.9251863310364224,0.7969888789102345\n",
      "300,8-8-8,8,85,0.9272957389959218,0.7972398884166977\n",
      "300,8-8-8,8,90,0.9281395021797215,0.798934732923582\n",
      "300,8-8-8,8,95,0.9278582477851216,0.8062466838495547\n",
      "300,8-8-8,8,100,0.9243425678526227,0.7877379896278388\n",
      "300,8-8-8,8,105,0.9257488398256223,0.8054062878107052\n",
      "300,8-8-8,9,20,0.9246238222472226,0.7995416952933466\n",
      "300,8-8-8,9,25,0.926592603009422,0.7998828754863112\n",
      "300,8-8-8,9,30,0.9271551117986219,0.7997714136930073\n",
      "300,8-8-8,9,35,0.9281395021797215,0.7984949902110339\n",
      "300,8-8-8,9,40,0.9271551117986219,0.7964786404497399\n",
      "300,8-8-8,9,45,0.9261707214175221,0.7956113253801426\n",
      "300,8-8-8,9,50,0.9303895373365209,0.811168946317145\n",
      "300,8-8-8,9,55,0.9274363661932218,0.7956672029056012\n",
      "300,8-8-8,9,60,0.9291238925608213,0.8195176030991203\n",
      "300,8-8-8,9,65,0.9257488398256223,0.7916271777660121\n",
      "300,8-8-8,9,70,0.9274363661932218,0.8158784672912224\n",
      "300,8-8-8,9,75,0.920123751933624,0.7880146943984975\n",
      "300,8-8-8,9,80,0.9249050766418225,0.7858771271374638\n",
      "300,8-8-8,9,85,0.9288426381662214,0.7937594544762328\n",
      "300,8-8-8,9,90,0.9237800590634229,0.7887423245384477\n",
      "300,8-8-8,9,95,0.926592603009422,0.7860763511863732\n",
      "300,8-8-8,9,100,0.9267332302067219,0.8000042835388183\n",
      "300,8-8-8,9,105,0.9270144846013219,0.8171267272130688\n",
      "300,8-8,3,20,0.9118267472929265,0.5096816852972571\n",
      "300,8-8,3,25,0.9414990859232175,0.8352657915476707\n",
      "300,8-8,3,30,0.9422022219097174,0.8464456283787193\n",
      "300,8-8,3,35,0.9414990859232175,0.8402982340154835\n",
      "300,8-8,3,40,0.943186612290817,0.8480542425272981\n",
      "300,8-8,3,45,0.9427647306989172,0.8441760083051228\n",
      "300,8-8,3,50,0.943608493882717,0.8485044996014307\n",
      "300,8-8,3,55,0.9438897482773169,0.8448720759642482\n",
      "300,8-8,3,60,0.9412178315286176,0.8461273845786986\n",
      "300,8-8,3,65,0.9339052172690199,0.8409297656271987\n",
      "300,8-8,3,70,0.9437491210800169,0.8498070134412928\n",
      "300,8-8,3,75,0.9440303754746168,0.8499329389488173\n",
      "300,8-8,3,80,0.9409365771340177,0.8454498650533376\n",
      "300,8-8,3,85,0.9406553227394178,0.8360187427817761\n",
      "300,8-8,3,90,0.9422022219097174,0.8485469047365012\n",
      "300,8-8,3,95,0.9393896779637182,0.8449258904385063\n",
      "300,8-8,3,100,0.9419209675151174,0.8446036674466715\n",
      "300,8-8,3,105,0.9422022219097174,0.8377807277302045\n",
      "300,8-8,4,20,0.9377021515961187,0.8406934888814396\n",
      "300,8-8,4,25,0.9410772043313177,0.8434086753774359\n",
      "300,8-8,4,30,0.9423428491070173,0.8440675258072902\n",
      "300,8-8,4,35,0.9405146955421179,0.8423248932907709\n",
      "300,8-8,4,40,0.9417803403178174,0.8436815516324642\n",
      "300,8-8,4,45,0.9419209675151174,0.8444933194242221\n",
      "300,8-8,4,50,0.9405146955421179,0.8410271788124392\n",
      "300,8-8,4,55,0.9412178315286176,0.8435115061079493\n",
      "300,8-8,4,60,0.9391084235691183,0.8402616888408959\n",
      "300,8-8,4,65,0.9357333708339193,0.8382679121508473\n",
      "300,8-8,4,70,0.939952186752918,0.8410781059727274\n",
      "300,8-8,4,75,0.9422022219097174,0.8395567167763495\n",
      "300,8-8,4,80,0.940233441147518,0.8430372826865389\n",
      "300,8-8,4,85,0.9414990859232175,0.8441370276590403\n",
      "300,8-8,4,90,0.9406553227394178,0.8408480419145167\n",
      "300,8-8,4,95,0.9419209675151174,0.842878694656615\n",
      "300,8-8,4,100,0.9400928139502179,0.8403889262679941\n",
      "300,8-8,4,105,0.9389677963718183,0.836135594583101\n",
      "300,8-8,5,20,0.9412178315286176,0.8407884707228553\n",
      "300,8-8,5,25,0.9391084235691183,0.8350357858753101\n",
      "300,8-8,5,30,0.9381240331880185,0.8363341115022216\n",
      "300,8-8,5,35,0.929967655744621,0.8231285001131137\n",
      "300,8-8,5,40,0.9374208972015188,0.8298436373870849\n",
      "300,8-8,5,45,0.9375615243988187,0.8364106201666948\n",
      "300,8-8,5,50,0.9396709323583181,0.8396126530186078\n",
      "300,8-8,5,55,0.9367177612150189,0.8306191345284869\n",
      "300,8-8,5,60,0.9375615243988187,0.8358179797335143\n",
      "300,8-8,5,65,0.9377021515961187,0.8311805990422343\n",
      "300,8-8,5,70,0.9388271691745184,0.836717270229717\n",
      "300,8-8,5,75,0.9368583884123189,0.8342991487181047\n",
      "300,8-8,5,80,0.9303895373365209,0.8326349581464486\n",
      "300,8-8,5,85,0.9378427787934186,0.8303351088142742\n",
      "300,8-8,5,90,0.9378427787934186,0.8330239054473192\n",
      "300,8-8,5,95,0.9369990156096188,0.8317339955776006\n",
      "300,8-8,5,100,0.9389677963718183,0.836486086906388\n",
      "300,8-8,5,105,0.9379834059907186,0.834388248446634\n",
      "300,8-8,6,20,0.9400928139502179,0.8386216685271717\n",
      "300,8-8,6,25,0.9382646603853185,0.8391405282984912\n",
      "300,8-8,6,30,0.9375615243988187,0.826411098068438\n",
      "300,8-8,6,35,0.9361552524258192,0.8308425841446816\n",
      "300,8-8,6,40,0.9378427787934186,0.8311861885194011\n",
      "300,8-8,6,45,0.9358739980312193,0.8355477330955156\n",
      "300,8-8,6,50,0.9341864716636198,0.8266730807916228\n",
      "300,8-8,6,55,0.9364365068204191,0.8264861354885603\n",
      "300,8-8,6,60,0.9270144846013219,0.8178235661449756\n",
      "300,8-8,6,65,0.9341864716636198,0.8250932895519435\n",
      "300,8-8,6,70,0.9350302348474195,0.8206548680593354\n",
      "300,8-8,6,75,0.9355927436366194,0.8216931727297778\n",
      "300,8-8,6,80,0.9358739980312193,0.8236783669049816\n",
      "300,8-8,6,85,0.9330614540852201,0.8203482125019628\n",
      "300,8-8,6,90,0.9360146252285192,0.8210999529726276\n",
      "300,8-8,6,95,0.9362958796231191,0.8247320114685436\n",
      "300,8-8,6,100,0.9341864716636198,0.8223777108654131\n",
      "300,8-8,6,105,0.9357333708339193,0.8236233868910053\n",
      "300,8-8,7,20,0.9337645900717199,0.8168924732233234\n",
      "300,8-8,7,25,0.9341864716636198,0.8195236469935789\n",
      "300,8-8,7,30,0.93334270847982,0.8086972280980573\n",
      "300,8-8,7,35,0.9327801996906202,0.8190738599524444\n",
      "300,8-8,7,40,0.9357333708339193,0.8256637434904629\n",
      "300,8-8,7,45,0.9355927436366194,0.8273805811285265\n",
      "300,8-8,7,50,0.9343270988609197,0.8275653168786213\n",
      "300,8-8,7,55,0.9334833356771199,0.8149605024083559\n",
      "300,8-8,7,60,0.9344677260582197,0.8267833740815812\n",
      "300,8-8,7,65,0.9317958093095204,0.8222165938443532\n",
      "300,8-8,7,70,0.9344677260582197,0.8251696794216236\n",
      "300,8-8,7,75,0.9367177612150189,0.8280893315638802\n",
      "300,8-8,7,80,0.9339052172690199,0.8239155608906322\n",
      "300,8-8,7,85,0.9346083532555196,0.8243533230584655\n",
      "300,8-8,7,90,0.9350302348474195,0.825725095111386\n",
      "300,8-8,7,95,0.9344677260582197,0.8261142499473207\n",
      "300,8-8,7,100,0.9306707917311208,0.8113490815990785\n",
      "300,8-8,7,105,0.9324989452960203,0.8188502945923158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300,8-8,8,20,0.9350302348474195,0.8281225560535906\n",
      "300,8-8,8,25,0.93334270847982,0.8259196471236055\n",
      "300,8-8,8,30,0.9312333005203206,0.8219258109900873\n",
      "300,8-8,8,35,0.9361552524258192,0.8268168343749235\n",
      "300,8-8,8,40,0.9313739277176206,0.8092703441484058\n",
      "300,8-8,8,45,0.9341864716636198,0.8216864082444765\n",
      "300,8-8,8,50,0.9353114892420195,0.8207310963616813\n",
      "300,8-8,8,55,0.9341864716636198,0.8229456385445276\n",
      "300,8-8,8,60,0.9337645900717199,0.8237194797940525\n",
      "300,8-8,8,65,0.9344677260582197,0.8256614904693516\n",
      "300,8-8,8,70,0.9344677260582197,0.8258408874733139\n",
      "300,8-8,8,75,0.9310926733230207,0.809489226604731\n",
      "300,8-8,8,80,0.9334833356771199,0.8226333529329954\n",
      "300,8-8,8,85,0.9347489804528196,0.8216961262864645\n",
      "300,8-8,8,90,0.9341864716636198,0.82659911980062\n",
      "300,8-8,8,95,0.9327801996906202,0.8203451841066731\n",
      "300,8-8,8,100,0.9350302348474195,0.8239378419827839\n",
      "300,8-8,8,105,0.9348896076501195,0.824612844421253\n",
      "300,8-8,9,20,0.9294051469554212,0.8054617097665163\n",
      "300,8-8,9,25,0.9343270988609197,0.8242143724614319\n",
      "300,8-8,9,30,0.9334833356771199,0.8180140713007912\n",
      "300,8-8,9,35,0.9346083532555196,0.820335267572338\n",
      "300,8-8,9,40,0.9361552524258192,0.8216799165942305\n",
      "300,8-8,9,45,0.9340458444663198,0.8195377778526293\n",
      "300,8-8,9,50,0.9355927436366194,0.8238426941193563\n",
      "300,8-8,9,55,0.9347489804528196,0.8246041946573319\n",
      "300,8-8,9,60,0.9354521164393194,0.8219693299465775\n",
      "300,8-8,9,65,0.9346083532555196,0.8195618612990566\n",
      "300,8-8,9,70,0.9351708620447194,0.8198303726946049\n",
      "300,8-8,9,75,0.9357333708339193,0.823436967929867\n",
      "300,8-8,9,80,0.9337645900717199,0.8156407652682075\n",
      "300,8-8,9,85,0.9323583180987203,0.8204728466406479\n",
      "300,8-8,9,90,0.9351708620447194,0.8218735245734621\n",
      "300,8-8,9,95,0.9347489804528196,0.8217038060633723\n",
      "300,8-8,9,100,0.9330614540852201,0.8216445392370106\n",
      "300,8-8,9,105,0.9361552524258192,0.8218516120596903\n",
      "300,4-4,3,20,0.9123892560821263,0.489751806199793\n",
      "300,4-4,3,25,0.923217550274223,0.5420982822049808\n",
      "300,4-4,3,30,0.9244831950499226,0.5468986996273976\n",
      "300,4-4,3,35,0.9146392912389256,0.5438601727521765\n",
      "300,4-4,3,40,0.9239206862607229,0.5474140488693776\n",
      "300,4-4,3,45,0.9242019406553227,0.5468250123377784\n",
      "300,4-4,3,50,0.9156236816200253,0.5445677543150768\n",
      "300,4-4,3,55,0.9206862607228238,0.5499976030702911\n",
      "300,4-4,3,60,0.9204050063282239,0.5469596385200949\n",
      "300,4-4,3,65,0.9225144142877233,0.5486721882115276\n",
      "300,4-4,3,70,0.9230769230769231,0.5436740735289006\n",
      "300,4-4,3,75,0.9226550414850232,0.547102887664332\n",
      "300,4-4,3,80,0.9244831950499226,0.5498828458632411\n",
      "300,4-4,3,85,0.9243425678526227,0.5491982000711763\n",
      "300,4-4,3,90,0.9206862607228238,0.529206425809322\n",
      "300,4-4,3,95,0.9209675151174237,0.5311328816074053\n",
      "300,4-4,3,100,0.9216706511039235,0.5285443036617478\n",
      "300,4-4,3,105,0.9227956686823232,0.5317115435849584\n",
      "300,4-4,4,20,0.9184362255660244,0.5323551030032623\n",
      "300,4-4,4,25,0.9181549711714245,0.5264800303063257\n",
      "300,4-4,4,30,0.9146392912389256,0.5277210884353741\n",
      "300,4-4,4,35,0.9208268879201238,0.5323381068631158\n",
      "300,4-4,4,40,0.9194206159471242,0.5289457146823918\n",
      "300,4-4,4,45,0.9212487695120236,0.5267794614802614\n",
      "300,4-4,4,50,0.920264379130924,0.5252207187714791\n",
      "300,4-4,4,55,0.9213893967093236,0.5280243637844406\n",
      "300,4-4,4,60,0.920123751933624,0.5281873888836354\n",
      "300,4-4,4,65,0.9211081423147237,0.5300020477282098\n",
      "300,4-4,4,70,0.9195612431444241,0.5264076645150814\n",
      "300,4-4,4,75,0.9150611728308254,0.5297743966289187\n",
      "300,4-4,4,80,0.9123892560821263,0.527451676787614\n",
      "300,4-4,4,85,0.919842497539024,0.5305057267634513\n",
      "300,4-4,4,90,0.9197018703417241,0.5263995210454854\n",
      "300,4-4,4,95,0.9192799887498242,0.5292246390698011\n",
      "300,4-4,4,100,0.9216706511039235,0.5319141982896208\n",
      "300,4-4,4,105,0.920264379130924,0.5280095257615667\n",
      "300,4-4,5,20,0.919983124736324,0.5306729682991375\n",
      "300,4-4,5,25,0.9188581071579244,0.5254541926143005\n",
      "300,4-4,5,30,0.9182955983687245,0.5274455747298152\n",
      "300,4-4,5,35,0.9125298832794262,0.5245399625485513\n",
      "300,4-4,5,40,0.9146392912389256,0.5284085478684407\n",
      "300,4-4,5,45,0.9185768527633245,0.5294471529017187\n",
      "300,4-4,5,50,0.919842497539024,0.5279662014543574\n",
      "300,4-4,5,55,0.919842497539024,0.5245939596917429\n",
      "300,4-4,5,60,0.916889326395725,0.5240781973030685\n",
      "300,4-4,5,65,0.9095767121361271,0.5216605346796005\n",
      "300,4-4,5,70,0.9154830544227254,0.5261936993871016\n",
      "300,4-4,5,75,0.9174518351849248,0.5230116811027282\n",
      "300,4-4,5,80,0.9171705807903249,0.5246438341471998\n",
      "300,4-4,5,85,0.9115454928983265,0.5259511550094512\n",
      "300,4-4,5,90,0.9095767121361271,0.5198132805286942\n",
      "300,4-4,5,95,0.9174518351849248,0.5256534675692391\n",
      "300,4-4,5,100,0.9167486991984249,0.5229677863363245\n",
      "300,4-4,5,105,0.9136549008578259,0.5219187067132603\n",
      "300,4-4,6,20,0.9156236816200253,0.5213012343520735\n",
      "300,4-4,6,25,0.9159049360146252,0.5187744614052062\n",
      "300,4-4,6,30,0.9159049360146252,0.5233936655347226\n",
      "300,4-4,6,35,0.9161861904092251,0.5229539039238468\n",
      "300,4-4,6,40,0.9160455632119252,0.5208901614253654\n",
      "300,4-4,6,45,0.9167486991984249,0.5184804201011907\n",
      "300,4-4,6,50,0.9133736464632259,0.518501133401422\n",
      "300,4-4,6,55,0.9153424272254254,0.5249721954477269\n",
      "300,4-4,6,60,0.9175924623822247,0.5207979648141604\n",
      "300,4-4,6,65,0.9153424272254254,0.5228090438020266\n",
      "300,4-4,6,70,0.916608072001125,0.521113210143521\n",
      "300,4-4,6,75,0.9177330895795247,0.5236546201763225\n",
      "300,4-4,6,80,0.9173112079876248,0.5234490738632362\n",
      "300,4-4,6,85,0.9109829841091267,0.5246599708175204\n",
      "300,4-4,6,90,0.9160455632119252,0.5209605498224553\n",
      "300,4-4,6,95,0.916467444803825,0.5243459052349282\n",
      "300,4-4,6,100,0.913514273660526,0.5209614205310045\n",
      "300,4-4,6,105,0.9171705807903249,0.5198108443715649\n",
      "300,4-4,7,20,0.9157643088173253,0.5229468380101471\n",
      "300,4-4,7,25,0.9308114189284208,0.7958300690638804\n",
      "300,4-4,7,30,0.9323583180987203,0.7890516448520035\n",
      "300,4-4,7,35,0.9157643088173253,0.5179706472389399\n",
      "300,4-4,7,40,0.9275769933905217,0.7858327257246737\n",
      "300,4-4,7,45,0.9178737167768246,0.5239332995612348\n",
      "300,4-4,7,50,0.9160455632119252,0.5230320198147621\n",
      "300,4-4,7,55,0.9161861904092251,0.5212352771457964\n",
      "300,4-4,7,60,0.9146392912389256,0.5208784679719566\n",
      "300,4-4,7,65,0.9157643088173253,0.5222438215634423\n",
      "300,4-4,7,70,0.9174518351849248,0.5232575911980972\n",
      "300,4-4,7,75,0.9161861904092251,0.5224893997039862\n",
      "300,4-4,7,80,0.9147799184362255,0.5209314874300978\n",
      "300,4-4,7,85,0.9153424272254254,0.522109145842638\n",
      "300,4-4,7,90,0.9157643088173253,0.5222438215634423\n",
      "300,4-4,7,95,0.9182955983687245,0.5239613644974045\n",
      "300,4-4,7,100,0.9147799184362255,0.5211773624496838\n",
      "300,4-4,7,105,0.9159049360146252,0.5227590203590861\n",
      "300,4-4,8,20,0.9156236816200253,0.5228284374724154\n",
      "300,4-4,8,25,0.9167486991984249,0.5213205426129129\n",
      "300,4-4,8,30,0.9289832653635213,0.7863360930629164\n",
      "300,4-4,8,35,0.9160455632119252,0.5202716316210307\n",
      "300,4-4,8,40,0.9149205456335255,0.5189994162787056\n",
      "300,4-4,8,45,0.9170299535930249,0.5206900387035357\n",
      "300,4-4,8,50,0.9133736464632259,0.5188224595552156\n",
      "300,4-4,8,55,0.913092392068626,0.517713805724722\n",
      "300,4-4,8,60,0.9121080016875264,0.5172801535878354\n",
      "300,4-4,8,65,0.913514273660526,0.5184071859828874\n",
      "300,4-4,8,70,0.9133736464632259,0.5206660528746417\n",
      "300,4-4,8,75,0.916889326395725,0.5216689170644464\n",
      "300,4-4,8,80,0.910139220925327,0.5198269691220693\n",
      "300,4-4,8,85,0.9143580368443257,0.5183880594128661\n",
      "300,4-4,8,90,0.9149205456335255,0.5209845068882388\n",
      "300,4-4,8,95,0.9159049360146252,0.5212686579272732\n",
      "300,4-4,8,100,0.9159049360146252,0.5202847368720683\n",
      "300,4-4,8,105,0.9163268176065251,0.5229621990401015\n",
      "300,4-4,9,20,0.9147799184362255,0.5202555862741746\n",
      "300,4-4,9,25,0.9142174096470257,0.5201845612222035\n",
      "300,4-4,9,30,0.9152018000281255,0.5209630052637092\n",
      "300,4-4,9,35,0.9146392912389256,0.5206311207508172\n",
      "300,4-4,9,40,0.9137955280551259,0.5178835790428169\n",
      "300,4-4,9,45,0.9146392912389256,0.5208093647839939\n",
      "300,4-4,9,50,0.9147799184362255,0.5209314874300978\n",
      "300,4-4,9,55,0.9149205456335255,0.5225411127915307\n",
      "300,4-4,9,60,0.9152018000281255,0.5225597054588229\n",
      "300,4-4,9,65,0.9150611728308254,0.5231143065972419\n",
      "300,4-4,9,70,0.9152018000281255,0.5219221418617189\n",
      "300,4-4,9,75,0.9163268176065251,0.5238829514098565\n",
      "300,4-4,9,80,0.9157643088173253,0.5230564281506909\n",
      "300,4-4,9,85,0.9154830544227254,0.5175981357885894\n",
      "300,4-4,9,90,0.9140767824497258,0.5185396688916283\n",
      "300,4-4,9,95,0.9080298129658276,0.5201721511151244\n",
      "300,4-4,9,100,0.913233019265926,0.515502324770829\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300,4-4,9,105,0.913514273660526,0.5171280253666353\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.random.seed(1337) # for reproducibility\n",
    "#Neural network functions for creating a prediction model\n",
    "from keras import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "#Evaluation metrics for checking classification model performance\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "#Operating system functions for interacting with folders and files\n",
    "import codecs\n",
    "import errno\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "\n",
    "#Check if the notebook path is already loaded\n",
    "try:  \n",
    "    noteBookPath\n",
    "except NameError:\n",
    "    print (\"NotebookPath variable dont exist, applying default one\")\n",
    "    noteBookPath= os.getcwd()\n",
    "    pass\n",
    "\n",
    "\n",
    "#Check if dataset path exist\n",
    "datasetFolder=\"dataset\"\n",
    "try:\n",
    "    datasetsPath=os.path.join(noteBookPath,datasetFolder) \n",
    "    if not os.path.isdir(datasetsPath): raise Exception(\"'Dataset' folder dont exist\")\n",
    "    else: \n",
    "        print (\"Directory: '\"+ datasetFolder+\"' exists\")\n",
    "        pass\n",
    "except SystemExit as e:\n",
    "    print(e)\n",
    "\n",
    "#Create experiments folder if not exists\n",
    "dirName=\"experiments\"\n",
    "try:\n",
    "    os.mkdir(os.path.join(noteBookPath,dirName) )\n",
    "    print (\"Directory: '\"+dirName+\"' Created\") \n",
    "except OSError as e:\n",
    "    if e.errno == errno.EEXIST:\n",
    "        print (\"Directory: '\"+ dirName+\"' exists\")\n",
    "        pass\n",
    "    else:\n",
    "        raise \n",
    "except:\n",
    "    print (\"Unexpected error\")\n",
    "    pass  \n",
    "\n",
    "#Check if the experiments folder path exist\n",
    "try:  \n",
    "    experimentsPath\n",
    "except NameError:\n",
    "    print (\"datasetPath variable dont exist, applying default one\")\n",
    "    experimentsPath=os.path.join(noteBookPath,dirName)\n",
    "    pass\n",
    "\n",
    "#Python Script\n",
    "try:\n",
    "    \n",
    "    #Parameters used for testing different Neural Network options\n",
    "    hiddenLayers=[[50,40,30,20,10],[50,25,10],[50,50],[16,8],[32,16,8],[8,8,8],[8,8],[4,4]]\n",
    "    batches=[x for x in range(20,110,5)]\n",
    "    epochs=[x for x in range(3,10,1)] \n",
    "    #Labels used to predict the structure of emails\n",
    "    structuralLabels=[\"Body\", \"Body/Intro\", \"Body/Outro\", \"Body/Signature\"]\n",
    "    #Mapping used for transforming values of the final NN layer to a specific structure category\n",
    "    structureMapping={0:\"Body\", 1:\"Body/Intro\", 2:\"Body/Outro\", 3:\"Body/Signature\"}\n",
    "    #Character ngram size\n",
    "    characterNgram=1\n",
    "    #Character embedding size vectors\n",
    "    featureNumbers=[300]\n",
    "    \n",
    "    #Iterate over each previously created Word-embedding file\n",
    "    for number in featureNumbers: \n",
    "        \n",
    "        print(\"Character embeddings experiments using vectors of size: \"+str(number))\n",
    "        \n",
    "        document = \"ResultsNgramGooglewithOwn-\"+str(characterNgram)+\"-EmbeddingSize-\"+str(number)+\".txt\"\n",
    "        filePath = os.path.join(experimentsPath,document)\n",
    "        \n",
    "        if not (os.path.isfile(filePath)):\n",
    "                \n",
    "            #List that have all the experimental results associate to a character embedding size\n",
    "            results=[]\n",
    "        \n",
    "            #Setting appropiate filepaths for experiments\n",
    "            document2 = \"ngram-\"+str(characterNgram)+\"TrainingVectorsSize-\"+str(number)+\".txt\"\n",
    "            filePath2 = os.path.join(experimentsPath,document2)\n",
    "        \n",
    "            document3 = \"ngram-\"+str(characterNgram)+\"TestVectorsSize-\"+str(number)+\".txt\"\n",
    "            filePath3 = os.path.join(experimentsPath,document3)\n",
    "            \n",
    "            if os.path.isfile(filePath2) and os.path.isfile(filePath3):\n",
    "                \n",
    "                #Test different variations of a Neural Network using training and test data\n",
    "                for layer in hiddenLayers:\n",
    "                    \n",
    "#                     #Read training vectors (Enron, JPL, etc.)\n",
    "#                     with codecs.open(filePath2,\"r\", \"ISO-8859-1\") as file:\n",
    "#                         vectors=[line.replace('\\n','') for line in file]\n",
    "                        \n",
    "# #                     trainingVectors=[[float(feature) for feature in vector.split(\",\")[4:]] \n",
    "# #                                                 for vector in vectors]\n",
    "#                     trainingLabels=[[int(feature) for feature in vector.split(\",\")[:4]] \n",
    "#                                                 for vector in vectors]\n",
    "                    trainingVectors=np.array(trainingVectors)\n",
    "                    trainingLabels=np.array(trainingLabels)\n",
    "                    \n",
    "                    #Read test vectors (Enron, JPL, etc.)\n",
    "#                     with codecs.open(filePath3,\"r\", \"ISO-8859-1\") as file:\n",
    "#                         vectors=[line.replace('\\n','') for line in file]\n",
    "#                     testVectors=[[float(feature) for feature in vector.split(\",\")[4:]] \n",
    "# #                                                 for vector in vectors]\n",
    "#                     testLabels=[[int(feature) for feature in vector.split(\",\")[:4]] \n",
    "#                                                 for vector in vectors]\n",
    "                    testVectors=np.array(testVectors) \n",
    "                    testLabels=np.array(testLabels)\n",
    "                    \n",
    "                    #Create the Neural Network architecture (Back-propagation approach)\n",
    "                    classifier = Sequential()\n",
    "                    #Hidden Layers\n",
    "                    classifier.add(Dense(layer[0], activation='relu', kernel_initializer='random_normal', input_dim=number))\n",
    "                    for element in layer[1:]:\n",
    "                        classifier.add(Dense(element, activation='relu', kernel_initializer='random_normal'))\n",
    "                        #Layer defined to avoid overfitting\n",
    "                        classifier.add(Dropout(0.2))\n",
    "                    #Output Layer\n",
    "                    classifier.add(Dense(4, activation='softmax', kernel_initializer='random_normal'))\n",
    "                    \n",
    "                    #Compiling the Neural Network\n",
    "                    classifier.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])\n",
    "                    \n",
    "                    #Choose the number of epochs\n",
    "                    for epoch in epochs:\n",
    "                        #Choose the number of batches to handle\n",
    "                        for batch in batches:\n",
    "\n",
    "                            #Create the prediction model\n",
    "                            classifier.fit(trainingVectors,trainingLabels, batch_size=batch, epochs=epoch,verbose=0)\n",
    "                            #Predict the age for each sample in the test dataset\n",
    "                            predictions = classifier.predict(testVectors)\n",
    "                            #Get the neuron id (0, 1 ,2 or 3) with the highest probability and then extract the age label\n",
    "                            predictedLabels=[structureMapping[np.argmax(x)] for x in predictions]\n",
    "                            expectedLabels=[structureMapping[np.argmax(x)] for x in testLabels]\n",
    "                            #Get model accuracy associated to each experiment\n",
    "                            accuracy=accuracy_score(expectedLabels, predictedLabels)\n",
    "                            \"\"\"\n",
    "                            Get F1-measure associated to each experiment\n",
    "                            \n",
    "                            F1 = 2 * (precision * recall) / (precision + recall)\n",
    "                            \n",
    "                            Calculate metrics for each label, and find their unweighted mean. This does not take \n",
    "                            label imbalance into account.\n",
    "                            \"\"\"\n",
    "                            f1=f1_score(expectedLabels, predictedLabels, average='macro')  \n",
    "                            #Get the confusion matrix associated to each experiment\n",
    "                            confusionMatrix=confusion_matrix(expectedLabels, predictedLabels, labels=structuralLabels)\n",
    "                            #Squish the matrix into a vector and then append all elements in a single string var\n",
    "                            confusionMatrix=\",\".join([str(x) for x in confusionMatrix.flatten()])\n",
    "                            #Print experimental results\n",
    "                            numberLayers=\"-\".join([str(x) for x in layer])\n",
    "                            res= (str(number)+\",\"+numberLayers+\",\"+str(epoch)+\",\"+str(batch)+\n",
    "                                 \",\"+str(accuracy)+\",\"+str(f1))\n",
    "                            print(res)      \n",
    "                            res=res+\",\"+confusionMatrix    \n",
    "                            results.append(res)\n",
    "\n",
    "                #Write experimental results to a file            \n",
    "                with codecs.open(filePath,\"w\", \"ISO-8859-1\") as file: \n",
    "                    [file.write(x+\"\\n\") for x in results]\n",
    "    \n",
    "            else: print (\"One of the following documents dont exist: \"+document2+\" or \"+document3)    \n",
    "            \n",
    "        else: print (\"The following document already exist: \"+document)\n",
    "\n",
    "except IOError as e:\n",
    "    print (\"Could not read file\")\n",
    "    print(traceback.format_exc())\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print (\"Unexpected error\")\n",
    "    print(traceback.format_exc())\n",
    "    print(e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6\\. Obtain best experimental results according to F1, Accuracy and confusion matrix values. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory: 'dataset' exists\n",
      "Directory: 'experiments' exists\n",
      "Get results of document: ResultsNgram-1-EmbeddingSize-100.txt\n",
      "Get results of document: ResultsNgram-1-EmbeddingSize-200.txt\n",
      "Get results of document: ResultsNgram-1-EmbeddingSize-300.txt\n",
      "Get results of document: ResultsNgram-1-EmbeddingSize-400.txt\n",
      "Get results of document: ResultsNgram-1-EmbeddingSize-500.txt\n",
      "Get results of document: ResultsNgram-1-EmbeddingSize-600.txt\n",
      "\n",
      "Total number of experiments: 6048\n",
      "\n",
      "Character embedding best experiments according to F1 values\n",
      "600,50-50,3,25,0.9471241738152159,0.8572802335170243,6137,5,119,0,9,131,19,0,221,3,467,0,0,0,0,0\n",
      "500,50-50,3,25,0.9462804106314161,0.8547510458144699,6122,6,133,0,10,131,18,0,210,5,476,0,0,0,0,0\n",
      "500,50-25-10,3,40,0.9459991562368162,0.8541479778232746,6127,4,130,0,12,130,17,0,216,5,470,0,0,0,0,0\n",
      "200,32-16-8,3,40,0.9464210378287161,0.8532098761903165,6130,6,125,0,12,130,17,0,216,5,470,0,0,0,0,0\n",
      "400,16-8,3,45,0.9429053578962171,0.8525906271999045,6100,7,154,0,9,133,17,0,216,3,472,0,0,0,0,0\n",
      "200,50-50,3,25,0.9462804106314161,0.852396893871263,6121,9,131,0,11,129,19,0,209,3,479,0,0,0,0,0\n",
      "600,50-50,3,75,0.9474054282098158,0.8520072330991234,6127,8,126,0,10,128,21,0,204,5,482,0,0,0,0,0\n",
      "600,32-16-8,3,45,0.9451553930530164,0.8517616316690333,6111,6,144,0,14,128,17,0,205,4,482,0,0,0,0,0\n",
      "600,50-40-30-20-10,3,40,0.946983546617916,0.8511953089954739,6129,10,122,0,10,129,20,0,211,4,476,0,0,0,0,0\n",
      "200,50-50,3,35,0.9451553930530164,0.8510638488887529,6129,5,127,0,11,132,16,0,224,7,460,0,0,0,0,0\n",
      "600,32-16-8,3,35,0.946702292223316,0.8509510289793316,6135,5,121,0,16,125,18,0,216,3,472,0,0,0,0,0\n",
      "600,50-40-30-20-10,4,20,0.9455772746449164,0.8508103194065612,6122,6,133,0,11,128,20,0,213,4,474,0,0,0,0,0\n",
      "400,8-8,3,25,0.9448741386584165,0.8508051447480779,6123,6,132,0,13,126,20,0,221,0,470,0,0,0,0,0\n",
      "300,50-50,3,45,0.9454366474476164,0.8507854519585337,6122,8,131,0,8,131,20,0,216,5,470,0,0,0,0,0\n",
      "600,50-50,3,45,0.946702292223316,0.8507532702212006,6135,9,117,0,10,131,18,0,219,6,466,0,0,0,0,0\n",
      "400,50-50,3,75,0.9452960202503164,0.850724446984143,6111,6,144,0,10,129,20,0,203,6,482,0,0,0,0,0\n",
      "400,16-8,4,25,0.9454366474476164,0.8501584896981695,6110,10,141,0,10,130,19,0,203,5,483,0,0,0,0,0\n",
      "500,16-8,3,45,0.9424834763043173,0.8500841650475787,6103,7,151,0,11,130,18,0,221,1,469,0,0,0,0,0\n",
      "600,50-40-30-20-10,4,30,0.9476866826044157,0.8499253787048658,6164,4,93,0,12,128,19,0,238,6,447,0,0,0,0,0\n",
      "400,50-25-10,3,80,0.9441710026719168,0.8497716504028903,6097,4,160,0,10,130,19,0,195,9,487,0,0,0,0,0\n",
      "500,16-8,3,50,0.943608493882717,0.8495361297178436,6113,7,141,0,11,130,18,0,221,3,467,0,0,0,0,0\n",
      "500,32-16-8,3,55,0.9452960202503164,0.8493568131858287,6103,7,151,0,11,129,19,0,193,8,490,0,0,0,0,0\n",
      "400,16-8,3,40,0.9440303754746168,0.8490054711893117,6131,7,123,0,11,131,17,0,237,3,451,0,0,0,0,0\n",
      "400,32-16-8,3,25,0.9451553930530164,0.8489995605394524,6138,7,116,0,13,129,17,0,234,3,454,0,0,0,0,0\n",
      "600,50-40-30-20-10,3,65,0.9457179018422163,0.8489731169497192,6133,7,121,0,12,128,19,0,223,4,464,0,0,0,0,0\n",
      "400,32-16-8,3,35,0.9440303754746168,0.8489520544423281,6133,3,125,0,13,128,18,0,236,3,452,0,0,0,0,0\n",
      "200,16-8,3,55,0.9443116298692167,0.848949766939206,6115,6,140,0,14,127,18,0,215,3,473,0,0,0,0,0\n",
      "600,32-16-8,3,50,0.9448741386584165,0.848912460976288,6114,6,141,0,16,127,16,0,208,5,478,0,0,0,0,0\n",
      "600,50-40-30-20-10,3,60,0.9464210378287161,0.8488754141861947,6127,6,128,0,10,126,23,0,209,5,477,0,0,0,0,0\n",
      "200,16-8,3,45,0.9452960202503164,0.8488098087446777,6131,6,124,0,12,127,20,0,224,3,464,0,0,0,0,0\n",
      "\n",
      "Best result Accuracy:0.9471241738152159\n",
      "Best result F1:0.8572802335170243\n",
      "Best confusion matrix\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWIAAAEmCAYAAABYlZoAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x252206f6ef0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "#sorting and list manipulation functions\n",
    "import operator\n",
    "#Operating system functions for interacting with folders and files\n",
    "import codecs\n",
    "import errno\n",
    "import os\n",
    "import sys\n",
    "import traceback\n",
    "#Mathematical functions to handle vectors\n",
    "import numpy as np\n",
    "#Plotting functions for visualizing results\n",
    "import matplotlib.pyplot as plt\n",
    "import itertools\n",
    "\n",
    "#Check if the notebook path is already loaded\n",
    "try:  \n",
    "    noteBookPath\n",
    "except NameError:\n",
    "    print (\"NotebookPath variable dont exist, applying default one\")\n",
    "    noteBookPath= os.getcwd()\n",
    "    pass\n",
    "\n",
    "#Check if dataset path exist\n",
    "datasetFolder=\"dataset\"\n",
    "try:\n",
    "    datasetsPath=os.path.join(noteBookPath,datasetFolder) \n",
    "    if not os.path.isdir(datasetsPath): raise Exception(\"'Dataset' folder dont exist\")\n",
    "    else: \n",
    "        print (\"Directory: '\"+ datasetFolder+\"' exists\")\n",
    "        pass\n",
    "except SystemExit as e:\n",
    "    print(e)\n",
    "\n",
    "#Create experiments folder if not exists\n",
    "dirName=\"experiments\"\n",
    "try:\n",
    "    os.mkdir(os.path.join(noteBookPath,dirName) )\n",
    "    print (\"Directory: '\"+dirName+\"' Created\") \n",
    "except OSError as e:\n",
    "    if e.errno == errno.EEXIST:\n",
    "        print (\"Directory: '\"+ dirName+\"' exists\")\n",
    "        pass\n",
    "    else:\n",
    "        raise \n",
    "except:\n",
    "    print (\"Unexpected error\")\n",
    "    pass  \n",
    "\n",
    "#Check if the experiments folder path exist\n",
    "try:  \n",
    "    experimentsPath\n",
    "except NameError:\n",
    "    print (\"datasetPath variable dont exist, applying default one\")\n",
    "    experimentsPath=os.path.join(noteBookPath,dirName)\n",
    "    pass\n",
    "\n",
    "#Python Script\n",
    "try:\n",
    "    \n",
    "    #Storage all results together in order to get the best ones\n",
    "    totalResults=[]\n",
    "    #Character ngram size\n",
    "    characterNgram=1\n",
    "    #Character embedding size vectors\n",
    "    featureNumbers=[100,200,300,400,500,600]\n",
    "    #Best results to display\n",
    "    numResults=30\n",
    "    #Labels used to predict the structure of emails\n",
    "    structuralLabels=[\"Body\", \"Body/Intro\", \"Body/Outro\", \"Body/Signature\"]\n",
    "    \n",
    "    #Iterate over each previously created result file\n",
    "    for number in featureNumbers:\n",
    "        \n",
    "        document = \"ResultsNgram-\"+str(characterNgram)+\"-EmbeddingSize-\"+str(number)+\".txt\"  \n",
    "        filePath = os.path.join(experimentsPath,document)\n",
    "        \n",
    "        if (os.path.isfile(filePath)):\n",
    "            \n",
    "            print(\"Get results of document: \"+ document)\n",
    "            \n",
    "            with codecs.open(filePath,\"r\", \"ISO-8859-1\") as file:\n",
    "                #Append each results (and its parameters) \n",
    "                documentResults=[((line.replace('\\n','')).split(\",\")) for line in file]\n",
    "            totalResults.extend(documentResults)\n",
    "    \n",
    "        else: print (\"The following document dont exist: \"+document)\n",
    "            \n",
    "    print(\"\\nTotal number of experiments: \"+str(len(totalResults))) \n",
    "    \n",
    "    #Order the experimental results by Accuracy, TP and TN\n",
    "    bestResults=sorted(totalResults, key=operator.itemgetter(5),reverse=True)\n",
    "    \n",
    "    print(\"\\nCharacter embedding best experiments according to F1 values\")\n",
    "    #Print ordered results\n",
    "    for values in bestResults[:numResults]:\n",
    "        print(\",\".join(values))      \n",
    "    \n",
    "    bestResult=bestResults[0]  \n",
    "    \n",
    "    print(\"\\nBest result Accuracy:\"+str(bestResult[4]))\n",
    "    print(\"Best result F1:\"+str(bestResult[5]))\n",
    "    print(\"Best confusion matrix\")\n",
    "    cm= (np.array([int(x) for x in bestResult[6:]])).reshape(4, 4)\n",
    "    #Plot the best confusion matrix\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "    plt.title('Character embedding best experiment')\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(structuralLabels))\n",
    "    plt.xticks(tick_marks, structuralLabels, rotation=45)\n",
    "    plt.yticks(tick_marks, structuralLabels)\n",
    "    fmt = '.2f' if False else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]),   range(cm.shape[1])):\n",
    "            plt.text(j, i, format(cm[i, j], fmt),horizontalalignment=\"center\",\n",
    "                    color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n",
    "    plt.show()\n",
    "\n",
    "except IOError as e:\n",
    "    print (\"Could not read file\")\n",
    "    print(traceback.format_exc())\n",
    "    print(e)\n",
    "except Exception as e:\n",
    "    print (\"Unexpected error\")\n",
    "    print(traceback.format_exc())\n",
    "    print(e) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Future/Alternative work\n",
    "\n",
    "Future research avenues includes some of the following:\n",
    "\n",
    "\n",
    "1\\. Analyze other dataset options for improving the model creation of the friend/foe classifier.\n",
    "\n",
    "2\\. Use other test data samples for checking the overall performance of the classifier over distinct types of emails.\n",
    "\n",
    "3\\. Use different supervised learning algorithms to improve classification (see: https://scikit-learn.org/stable/supervised_learning.html).\n",
    "\n",
    "4\\. Use other Neural Network architectures and methods to improve results.\n",
    "\n",
    "5\\. Improve error handling in the implemented Python code.\n",
    "\n",
    "6\\. Considering that are millions of emails/texts in the project (very likely) (https://ased.io/) it is necessary to use parallel techniques to distribute the classification work (see: https://spark.apache.org/ or http://docs.dask.org/en/latest/why.html)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
